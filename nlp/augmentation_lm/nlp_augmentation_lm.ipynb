{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_augmentation_lm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXro9efVU84k"
      },
      "source": [
        "# üìà: Text Augmentation using large-scale LMs and prompt engineering\n",
        "\n",
        "This notebook looks into the possibility of performing data augmentation on an NLP dataset leveraging the few-shot capabilities of large-scale language models (LMs) and prompt engineering üí°.\n",
        "\n",
        "Data augmentation techniques are used to generate additional samples. Data augmentation is already standard practice in computer vision projects üëÄ, but can also be leveraged in many NLP problems. We'll use a limited training set to simulate a real-world use case, where we are often constrained by the size of the available data ü§¶."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acwqGIAyU84m"
      },
      "source": [
        "## üõ†Ô∏è Getting started\n",
        "\n",
        "The cells below will setup everything that is required to get started with data augmentation and finetuning an NLP model with the HuggingFace API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIDjl_wU84m"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-ItvjqP4Cxn"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.12.5 datasets==1.16.1 tokenizers==0.10.3 openai==0.11.3 requests==2.23.0 sentencepiece==0.1.96\n",
        "!pip install pandas==1.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir6zD__FU84n"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hM-09Chsj7wI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pickle\n",
        "import random\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from datasets import load_dataset, concatenate_datasets, load_from_disk, load_metric, Dataset, ClassLabel\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, TrainerCallback, AutoModelForCausalLM, AutoModelForSeq2SeqLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFQ6LEgjeRWb"
      },
      "source": [
        "### Download dataset\n",
        "We'll train and evaluate our models on [Emotion](https://huggingface.co/datasets/emotion) dataset that contains English Twitter messages labeled as one of the six basic emotions: anger, fear, joy, love, sadness and surprise. To reduce the complexity of the task, we will keep only three labels, namely:\n",
        "- joy üòÇ\n",
        "- anger üò†\n",
        "- surprise üòØ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ltsurmvaaGd"
      },
      "outputs": [],
      "source": [
        "# load the dataset and filter on samples that have a token count less than 30 \n",
        "# to use only short tweets\n",
        "max_input_len = 30\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "emotion_ds = load_dataset(\"emotion\").filter(lambda e: len(tokenizer.batch_encode_plus([e['text']]).input_ids[0]) < int(max_input_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ24-mWS6elF"
      },
      "source": [
        "The dataset is already split into 16,000 train and 2,000 test samples. To investigate the effectiveness of the augmentation method, we will use only 10 samples per class as a train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YI6-pZdSqnI"
      },
      "outputs": [],
      "source": [
        "# select 10 random train samples from each of the three emotions\n",
        "# SADNESS = 0\n",
        "# JOY = 1\n",
        "# LOVE = 2\n",
        "# ANGER = 3\n",
        "# FEAR = 4\n",
        "# SURPRISE = 5 \n",
        "\n",
        "joy_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 1).shuffle(seed=42).select(range(10))\n",
        "anger_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 3).shuffle(seed=42).select(range(10))\n",
        "surprise_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 5).shuffle(seed=42).select(range(10))\n",
        "\n",
        "# map emotions to integers for labeling\n",
        "# joy (0), anger (1), surprise (2)\n",
        "def map_emotions(example):\n",
        "    if example['label'] == 1: # joy\n",
        "        example['label'] = 0\n",
        "    elif example['label'] == 3: # anger\n",
        "        example['label'] = 1\n",
        "    else: \n",
        "        example['label'] = 2 # surprise\n",
        "    return example\n",
        "\n",
        "# create a train set that consists of 10 samples per class and filter the test \n",
        "# set to contain only the valid labels\n",
        "emotion_train_ds = concatenate_datasets([joy_train_samples, anger_train_samples, surprise_train_samples]).map(lambda e: map_emotions(e)).shuffle(seed=42)\n",
        "emotion_test_ds = emotion_ds[\"test\"].filter(lambda e: e['label'] in [1, 3, 5]).map(lambda e: map_emotions(e))\n",
        "\n",
        "# define the maping between emotions and labels\n",
        "mapping = ClassLabel(names=['joy', 'anger', 'surprise'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi2XjbC69Of5"
      },
      "source": [
        "Before proceeding with the data augmentation, let's have a look into the baseline dataset üòé!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD2xmdrg9OLY",
        "outputId": "bccebaf5-a76e-4dda-c29e-3c02de5dfd8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set\n",
            "Total samples: 30\n",
            "\n",
            "A random sample\n",
            "Text: i feel angered and firey \n",
            "Label: anger\n",
            "\n",
            "\n",
            "Test set\n",
            "Total samples: 797\n",
            "\n",
            "A random sample\n",
            "Text: i feel more virtuous than when i eat veggies dipped in hummus \n",
            "Label: joy\n"
          ]
        }
      ],
      "source": [
        "print(\"Train set\")\n",
        "print(f\"Total samples: {len(emotion_train_ds)}\\n\")\n",
        "print(\"A random sample\")\n",
        "print(f\"Text: {emotion_train_ds['text'][10]} \\nLabel: {mapping.int2str(emotion_train_ds['label'][10])}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Test set\")\n",
        "print(f\"Total samples: {len(emotion_test_ds)}\\n\")\n",
        "print(\"A random sample\")\n",
        "print(f\"Text: {emotion_test_ds['text'][10]} \\nLabel: {mapping.int2str(emotion_test_ds['label'][10])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIJPd8P9S9kW"
      },
      "source": [
        "## Text Augmentation pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkx02t5Z3ZVN"
      },
      "source": [
        "We will leverage the few-shot capabilities of large LMs to generate synthetic but very realistic samples from a mixture of real samples. Specifically, we select two real samples from our dataset and embed these samples in a carefully designed prompt. Then, the LM takes as input the prompt and generates an augmented mixed sample influenced by the sample sentences.\n",
        "\n",
        "\n",
        "Generally, a prompt looks like this:\n",
        "\n",
        "    Each item in the following list contains a <text type> and the\n",
        "    respective <label type>. <label type> is one of ‚Äô<label token 1>‚Äô,\n",
        "    ..., or ‚Äô<label token N>‚Äô. \n",
        "    <text type>: <example text 1> (<label type>: <example label 1>)\n",
        "    ...\n",
        "    <text type>: <example text k> (<label type>: <example label k>)\n",
        "    <text type>:\n",
        "\n",
        "In our case the prompt looks like this:\n",
        "\n",
        "    Each item in the following list contains a tweet and the\n",
        "    respective sentiment. Sentiment is one of ‚Äôjoy‚Äô, 'surprise' or 'anger'. \n",
        "    Tweet: i feel angered and firey (Sentiment: anger)\n",
        "    Tweet: im feeling very peaceful about our wedding again now after having (Sentiment: joy)\n",
        "    Tweet:\n",
        "\n",
        "You can find more information on text augmentation using large LMs in [GPT3Mix](https://arxiv.org/abs/2104.08826) paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj2Of7vGILFJ"
      },
      "source": [
        "First, we should extract pairs of samples from the train set. There are various extraction strategies that can be used to increase the quality of the synthetic samples. We will simply extract the pairs randomly since by repeating random sampling a diverse synthetic dataset will be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlI7GYwbGx5m"
      },
      "outputs": [],
      "source": [
        "def get_two_random_samples():\n",
        "    # define a function that returns two random samples from the train set.\n",
        "    s1, s2 = random.sample(range(0, len(emotion_train_ds)), 2)\n",
        "    return emotion_train_ds['text'][s1], emotion_train_ds['label'][s1], emotion_train_ds['text'][s2], emotion_train_ds['label'][s2]\n",
        "\n",
        "def get_prompt(text1, label1, text2, label2):\n",
        "    # define a function that takes as input two samples and generates the prompt\n",
        "    # that we should pass to the GPT-3 language model for completion.\n",
        "    description = \"Each item in the following list contains a tweet and the respective sentiment. Sentiment is one of 'joy', 'surprise' or 'anger'.\"\n",
        "    prompt = (f\"{description}\\n\"\n",
        "            f\"Tweet: {text1} (Sentiment: {mapping.int2str(label1)})\\n\"\n",
        "            f\"Tweet: {text2} (Sentiment: {mapping.int2str(label2)})\\n\"\n",
        "            f\"Tweet:\")\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9xNf9D4jY00"
      },
      "source": [
        "### GPT-3\n",
        "\n",
        "We will leverage [GPT-3](https://openai.com/blog/openai-api/) that is a powerful model developed by Open AI and an excellent few-shot learner allowing it to be controlled via natural text prompts. We will generate 10, 50, 100 and 200 synthetic samples using the OpenAI API.\n",
        "\n",
        "**Disclaimer:** You need a key to make requests to OpenAI API. You can request a key [here](https://beta.openai.com/docs/developer-quickstart) or you just can load the synthetic samples that we generated in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAzLn9t83YCS"
      },
      "outputs": [],
      "source": [
        "# define the number of synthetic samples to generate\n",
        "n = 10\n",
        "new_texts = []\n",
        "new_labels = []\n",
        "api_key = # insert your api key for GPT-3\n",
        "headers = {'Authorization' : 'Bearer ' + api_key,\n",
        "              'Content-type':'application/json', \n",
        "              'Accept':'application/json'}\n",
        "\n",
        "iter = 0\n",
        "while iter < n:\n",
        "    # select two random samples from training set\n",
        "    text1, label1, text2, label2 = get_two_random_samples()\n",
        "    # create the prompt\n",
        "    prompt = get_prompt(text1, label1, text2, label2)\n",
        "    # send a post request to gpt-3 using the prompt\n",
        "    response = requests.post('https://api.openai.com/v1/engines/davinci/completions',\n",
        "                             headers=headers,\n",
        "                             data = json.dumps({\"prompt\": prompt, \n",
        "                                                \"max_tokens\": 30,\n",
        "                                                \"temperature\": 0.9,\n",
        "                                                \"top_p\": 0.95}))\n",
        "\n",
        "    # get response and extract the generated text and label\n",
        "    # the generated output will be in the form \"<text> (Sentiment: <label>)\"\n",
        "    data = response.json()['choices'][0]['text'].split('\\n')[0].split('(Sentiment:')\n",
        "\n",
        "    if len(data) < 2:\n",
        "        # the format of the response is invalid\n",
        "        continue\n",
        "\n",
        "    text = data[0]\n",
        "    label = data[1].split(')')[0].strip()\n",
        "\n",
        "    if label not in ['joy', 'anger', 'surprise']:\n",
        "        # the format of the response is invalid\n",
        "        continue\n",
        "\n",
        "    new_texts.append(text)\n",
        "    new_labels.append(mapping.str2int(label))\n",
        "    iter += 1\n",
        "\n",
        "# define the synthetic dataset and save it to disk so as to prevent sending \n",
        "# many api requests\n",
        "synthetic_ds = Dataset.from_dict({'text': new_texts, 'label': new_labels})\n",
        "synthetic_ds.save_to_disk('./data/gpt-3/' + str(n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPlF7dXKor6v"
      },
      "outputs": [],
      "source": [
        "# load the synthetic datasets with 10, 50, 100 and 200 samples\n",
        "# run this if you do not want to generate samples on your own.\n",
        "\n",
        "if not os.path.isdir('./data'):\n",
        "    !git clone https://github.com/ml6team/quick-tips.git\n",
        "    !cd quick-tips \n",
        "    !mv quick-tips/nlp/augmentation_lm/data ./data\n",
        "    !rm -rf quick-tips\n",
        "\n",
        "synthetic_gpt3_10_ds = load_from_disk('./data/gpt-3/10')\n",
        "synthetic_gpt3_50_ds = load_from_disk('./data/gpt-3/50')\n",
        "synthetic_gpt3_100_ds = load_from_disk('./data/gpt-3/100')\n",
        "synthetic_gpt3_200_ds = load_from_disk('./data/gpt-3/200')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b4GsUwfINep"
      },
      "source": [
        "Now let's print some synthetic samples to examine their quality!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ug42-3M0TeU"
      },
      "outputs": [],
      "source": [
        "def print_random_sample(ds):\n",
        "    # function that prints a random sample from a dataset\n",
        "    idx = random.randint(0, len(ds)-1)\n",
        "    print(f\"Text: {ds['text'][idx]} \\nLabel: {mapping.int2str(ds['label'][idx])}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6irrOSPrKVU9",
        "outputId": "39eab1b3-ddf5-4cfc-a42c-a013e7af083e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset of 10 synthetic samples:\n",
            "Text:  even if ur not into these kind of things u have to admit it's pretty cool  \n",
            "Label: joy\n",
            "\n",
            "Dataset of 50 synthetic samples:\n",
            "Text:  i just feel like every time they get off my car they're just ripping me off  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 100 synthetic samples:\n",
            "Text:  i've had this knot in my stomach all week. i thought it was indigestion  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 200 synthetic samples:\n",
            "Text:  20% or more electricity costs due to inefficient appliances and systems. #green #efficiency #Smarthome  \n",
            "Label: anger\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset of 10 synthetic samples:\")\n",
        "print_random_sample(synthetic_gpt3_10_ds)\n",
        "print(\"Dataset of 50 synthetic samples:\")\n",
        "print_random_sample(synthetic_gpt3_50_ds)\n",
        "print(\"Dataset of 100 synthetic samples:\")\n",
        "print_random_sample(synthetic_gpt3_100_ds)\n",
        "print(\"Dataset of 200 synthetic samples:\")\n",
        "print_random_sample(synthetic_gpt3_200_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6dLc7xMK0NJ"
      },
      "source": [
        "We see that GPT-3 has effectively generated very realistic samples. üëèüëèüëè"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PaeBV_AWb_-"
      },
      "source": [
        "### GPT-Neo\n",
        "\n",
        "An open-source alternative of GPT-3 is [GPT-Neo](https://www.eleuther.ai/projects/gpt-neo/) by a group called Eleuther AI. The goal of the group is to democratize huge LMs, so they made GPT-Neo publicly available. GPT-3 on the other hand is not openly available at the time. To use GPT-Neo, we can load it through HuggingFace. \n",
        "\n",
        "**Disclaimer:** To use GPT-Neo, it would take at least 25GB of CPU RAM to just load the model. So, it might not be able to load it in a regular notebook. In case you want to avoid that, you just can load the synthetic samples that we generated in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnYf0vZdHGiK"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
        "model = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
        "\n",
        "# define the number of synthetic samples to generate\n",
        "n = 10\n",
        "new_texts = []\n",
        "new_labels = []\n",
        "\n",
        "iter = 0\n",
        "while iter < n:\n",
        "    # select two random samples from training set\n",
        "    text1, label1, text2, label2 = get_two_random_samples()\n",
        "    # create the prompt\n",
        "    prompt = get_prompt(text1, label1, text2, label2)\n",
        "\n",
        "    # generate text using GPT-J model\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=100,)\n",
        "    gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
        "    # the generated output will be in the form \"<text> (Sentiment: <label>)\"\n",
        "    data = gen_text.split('\\n')[3].strip('Tweet: ').split('(Sentiment:')\n",
        "    if len(data) < 2:\n",
        "        # the format of the response is invalid\n",
        "        continue\n",
        "\n",
        "    text = data[0]\n",
        "    label = data[1].split(')')[0].strip()\n",
        "    if label not in ['joy', 'anger', 'surprise']:\n",
        "        # the format of the response is invalid\n",
        "        continue\n",
        "\n",
        "    new_texts.append(text)\n",
        "    new_labels.append(mapping.str2int(label))\n",
        "    iter += 1\n",
        "\n",
        "\n",
        "# define the synthetic dataset and save it to disk \n",
        "synthetic_ds = Dataset.from_dict({'text': new_texts, 'label': new_labels})\n",
        "synthetic_ds.save_to_disk('./data/gpt-neo/' + str(n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MncjIfEcHRsM"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('./data'):\n",
        "    !git clone https://github.com/ml6team/quick-tips.git\n",
        "    !cd quick-tips\n",
        "    !mv quick-tips/nlp/augmentation_lm/data ./data\n",
        "    !rm -rf quick-tips\n",
        "\n",
        "synthetic_gptneo_10_ds = load_from_disk('./data/gpt-neo/10')\n",
        "synthetic_gptneo_50_ds = load_from_disk('./data/gpt-neo/50')\n",
        "synthetic_gptneo_100_ds = load_from_disk('./data/gpt-neo/100')\n",
        "synthetic_gptneo_200_ds = load_from_disk('./data/gpt-neo/200')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhdkFMCpHeuO",
        "outputId": "17e35fec-2119-4bac-de45-18d1d0d10233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset of 10 synthetic samples:\n",
            "Text: happy friday :)  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 50 synthetic samples:\n",
            "Text: his is the easiest time of year to feel unsatisfied  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 100 synthetic samples:\n",
            "Text: he new version of google chat is out  \n",
            "Label: surprise\n",
            "\n",
            "Dataset of 200 synthetic samples:\n",
            "Text: I'm feeling happy and excited  \n",
            "Label: surprise\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset of 10 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptneo_10_ds)\n",
        "print(\"Dataset of 50 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptneo_50_ds)\n",
        "print(\"Dataset of 100 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptneo_100_ds)\n",
        "print(\"Dataset of 200 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptneo_200_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbMrIov5ON6M"
      },
      "source": [
        "GPT-Neo generates realistic samples! However, we can see that there are cases that the label is wrong (example 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5alF-lekkIr"
      },
      "source": [
        "### GPT-J\n",
        "\n",
        "A third alternative is [GPT-J](https://6b.eleuther.ai/), which was also made and released by Eleuther AI. Like GPT-Neo, we can access GPT-J through HuggingFace.\n",
        "\n",
        "**Disclaimer:** To load GPT-J, it would take at least 48GB of CPU RAM to just load the model. So, it might not be able to load it in a regular notebook. In case you want to avoid that, you just can load the synthetic samples that we generated in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7QKbaaekqCr"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "\n",
        "# define the number of synthetic samples to generate\n",
        "n = 10\n",
        "new_texts = []\n",
        "new_labels = []\n",
        "\n",
        "iter = 0\n",
        "while iter < n:\n",
        "    # select two random samples from training set\n",
        "    text1, label1, text2, label2 = get_two_random_samples()\n",
        "    # create the prompt\n",
        "    prompt = get_prompt(text1, label1, text2, label2)\n",
        "\n",
        "    # generate text using GPT-J model\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=100,)\n",
        "    gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
        "    # the generated output will be in the form \"<text> (Sentiment: <label>)\"\n",
        "    data = gen_text.split('\\n')[3].strip('Tweet: ').split('(Sentiment:')\n",
        "    if len(data) < 2:\n",
        "        # the format of the response is invalid\n",
        "        continue\n",
        "\n",
        "    text = data[0]\n",
        "    label = data[1].split(')')[0].strip()\n",
        "    if label not in ['joy', 'anger', 'surprise']:\n",
        "        # the format of the response is invalid\n",
        "        continue\n",
        "\n",
        "    new_texts.append(text)\n",
        "    new_labels.append(mapping.str2int(label))\n",
        "    iter += 1\n",
        "\n",
        "# define the synthetic dataset and save it to disk \n",
        "synthetic_ds = Dataset.from_dict({'text': new_texts, 'label': new_labels})\n",
        "synthetic_ds.save_to_disk('./data/gpt-j/' + str(n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu0JVPbQk1zB"
      },
      "outputs": [],
      "source": [
        "# load the synthetic datasets with 10, 50, 100 and 200 samples\n",
        "# run this if you do not want to generate new samples on your own.\n",
        "\n",
        "if not os.path.isdir('./data'):\n",
        "    !git clone https://github.com/ml6team/quick-tips.git\n",
        "    !cd quick-tips\n",
        "    !mv quick-tips/nlp/augmentation_lm/data ./data\n",
        "    !rm -rf quick-tips\n",
        "\n",
        "synthetic_gptj_10_ds = load_from_disk('./data/gpt-j/10')\n",
        "synthetic_gptj_50_ds = load_from_disk('./data/gpt-j/50')\n",
        "synthetic_gptj_100_ds = load_from_disk('./data/gpt-j/100')\n",
        "synthetic_gptj_200_ds = load_from_disk('./data/gpt-j/200')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpq3vNSMFWx_",
        "outputId": "cc7a8607-81e5-4999-f05d-94916e691297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset of 10 synthetic samples:\n",
            "Text: i think it s the easiest time of year to feel dissatisfied  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 50 synthetic samples:\n",
            "Text: i feel great  \n",
            "Label: joy\n",
            "\n",
            "Dataset of 100 synthetic samples:\n",
            "Text: i'm surprised and have to say \"hmmm\"  \n",
            "Label: surprise\n",
            "\n",
            "Dataset of 200 synthetic samples:\n",
            "Text: i get giddy over feeling elegant in a beautifully cut pencil skirt  \n",
            "Label: joy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset of 10 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptj_10_ds)\n",
        "print(\"Dataset of 50 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptj_50_ds)\n",
        "print(\"Dataset of 100 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptj_100_ds)\n",
        "print(\"Dataset of 200 synthetic samples:\")\n",
        "print_random_sample(synthetic_gptj_200_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygrmMapNJrsg"
      },
      "source": [
        "Even though GPT-J is much smaller than GPT-3, it manages to generate high quality samples üëè."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gesWuhM9jbLq"
      },
      "source": [
        "## üöÄ Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QaSNzfSTG4D"
      },
      "source": [
        "Here we define the model and the training pipeline. We will use [DistilBERT](https://arxiv.org/abs/1910.01108) which is a light Transformer trained by distilling BERT base. It has 40% fewer parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT‚Äôs performances as measured on the GLUE language understanding benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xqcEiJqBZsB"
      },
      "outputs": [],
      "source": [
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "batch_size = 8\n",
        "max_size = 200 # size of the largest augmented dataset\n",
        "steps = 5*int(max_size/batch_size) # 5 epochs in the large dataset\n",
        "\n",
        "run_dicts = [] # list of dicts to store both metrics and logs for all the experiment runs \n",
        "\n",
        "# prepare synthetic datasets\n",
        "datasets_gpt3 = {'10': synthetic_gpt3_10_ds, '50': synthetic_gpt3_50_ds, '100': synthetic_gpt3_100_ds, '200': synthetic_gpt3_200_ds}\n",
        "datasets_gptneo = {'10': synthetic_gptneo_10_ds, '50': synthetic_gptneo_50_ds, '100': synthetic_gptneo_100_ds, '200': synthetic_gptneo_200_ds}\n",
        "datasets_gptj = {'10': synthetic_gptj_10_ds, '50': synthetic_gptj_50_ds, '100': synthetic_gptj_100_ds, '200': synthetic_gptj_200_ds}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFQdGZMbqoot"
      },
      "source": [
        "**Disclaimer:** In case you don't want to train the models again, you can import our results by running only this cell and ignoring the other cells of this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fwya_HG1qm0O"
      },
      "outputs": [],
      "source": [
        "# run this if you do not want to train the models on your own.\n",
        "if not os.path.isdir('./results'):\n",
        "    !git clone https://github.com/ml6team/quick-tips.git\n",
        "    !cd quick-tips\n",
        "    !mv quick-tips/nlp/augmentation_lm/results ./results\n",
        "    !rm -rf quick-tips\n",
        "\n",
        "run_dicts = pickle.load(open('./results/run_dicts.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-q6U8DAx0Jp"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "        Calculates the accuracy of the model's predictions, calculated as follows; \n",
        "                        (TP + TN) / (TP + TN + FP + FN) \n",
        "        with TP: True positive TN: True negative FP: False positive FN: False negative\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels) \n",
        "\n",
        "\n",
        "class LogAccumulatorCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    A class that stores both the training and the evaluation loss\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.acc_logs = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero and ('loss' in logs or 'eval_loss' in logs):\n",
        "            self.acc_logs.append(logs.copy())\n",
        "\n",
        "\n",
        "def train_and_evaluate(train_ds, test_ds, identifier):\n",
        "    def tokenize(batch):\n",
        "        return tokenizer(batch['text'], padding=True, truncation=True)\n",
        "    \n",
        "    train_ds = train_ds.map(tokenize, batched=True, batch_size=len(train_ds), remove_columns=[\"text\"])\n",
        "    test_ds = test_ds.map(tokenize, batched=True, batch_size=len(test_ds), remove_columns=[\"text\"])\n",
        "    \n",
        "    training_args = TrainingArguments(\n",
        "        identifier,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        logging_strategy=\"steps\",\n",
        "        weight_decay=0.01,\n",
        "        learning_rate=1e-4,\n",
        "        max_steps=steps,\n",
        "        logging_steps=20\n",
        "    )\n",
        "    \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
        "\n",
        "    # Partially freezing the weights of initial layers of the model\n",
        "    # Since we're working on small datasets as it usually reduces overfitting\n",
        "    # Another advantage of partial freezing is reduced memory usage and \n",
        "    # a speed improvement during training.\n",
        "    for block in model.distilbert.embeddings.modules():\n",
        "        for param in block.parameters():\n",
        "            param.requires_grad=False\n",
        "\n",
        "    for i in [0,1,2]:\n",
        "        for block in model.distilbert.transformer.layer[i].modules():\n",
        "            for param in block.parameters():\n",
        "                param.requires_grad=False\n",
        "\n",
        "            \n",
        "    logger = LogAccumulatorCallback()\n",
        "    trainer = Trainer(\n",
        "        model=model, args=training_args, \n",
        "        train_dataset=train_ds, \n",
        "        eval_dataset=test_ds,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[logger],\n",
        "    )\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    \n",
        "    return metrics, logger.acc_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIp57un2x7Qy",
        "outputId": "9254321f-4eb6-4cca-88d8-db0b6776db97"
      },
      "source": [
        "### Model baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mDmH_lwU84r"
      },
      "outputs": [],
      "source": [
        "# train our model on the baseline dataset without augmentation\n",
        "metrics, logs = train_and_evaluate(emotion_train_ds, emotion_test_ds, \"baseline\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"baseline\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jge5A7tfo5Qp"
      },
      "source": [
        "### Model with augmented data of GPT-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9VpXbJUW_7O"
      },
      "outputs": [],
      "source": [
        "# train the model on the augmented datasets of GPT-3\n",
        "for i in datasets_gpt3:\n",
        "    augmented_gpt3_ds = concatenate_datasets([emotion_train_ds, datasets_gpt3[i]])\n",
        "    metrics, logs = train_and_evaluate(augmented_gpt3_ds, emotion_test_ds, \"augmented_gpt3_\" + i)\n",
        "\n",
        "    run_dicts.append({\n",
        "        \"id\": \"augmented_gpt3_\" + i,\n",
        "        \"metrics\": metrics,\n",
        "        \"logs\": logs\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_zFaIeVhWiF"
      },
      "source": [
        "### Model with augmented data of GPT-Neo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFCr4PLRhXc2"
      },
      "outputs": [],
      "source": [
        "# train our model on the augmented datasets of GPT-Neo\n",
        "for i in datasets_gptneo:\n",
        "    augmented_gptneo_ds = concatenate_datasets([emotion_train_ds, datasets_gptneo[i]])\n",
        "    metrics, logs = train_and_evaluate(augmented_gptneo_ds, emotion_test_ds, \"augmented_gptneo_\" + i)\n",
        "\n",
        "    run_dicts.append({\n",
        "        \"id\": \"augmented_gptneo_\" + i,\n",
        "        \"metrics\": metrics,\n",
        "        \"logs\": logs\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvuiZAQLzWhq"
      },
      "source": [
        "### Model with augmented data of GPT-J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzjoYX46egsA"
      },
      "outputs": [],
      "source": [
        "# train the model on the augmented datasets of GPT-J\n",
        "for i in datasets_gptj:\n",
        "    augmented_gptj_ds = concatenate_datasets([emotion_train_ds, datasets_gptj[i]])\n",
        "    metrics, logs = train_and_evaluate(augmented_gptj_ds, emotion_test_ds, \"augmented_gptj_\" + i)\n",
        "\n",
        "    run_dicts.append({\n",
        "        \"id\": \"augmented_gptj_\" + i,\n",
        "        \"metrics\": metrics,\n",
        "        \"logs\": logs\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hFLaimXfRwn"
      },
      "source": [
        "##  üìä Visualize\n",
        "\n",
        "To evaluate the effectiveness of text augmentation in the performance of the model, we'll visualize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XWA9lDzFWqG"
      },
      "source": [
        "### Model Performance\n",
        "\n",
        "Now let's compare the performance of the trained models. First, we will examine the accuracy improvements of text augmentation using GPT-3, GPT-J and GPT-Neo and then we will compare the three methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ROh9zOSfMwE"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(run_dicts)\n",
        "\n",
        "gpt3_names = ['augmented_gpt3_10', 'augmented_gpt3_50', 'augmented_gpt3_100', 'augmented_gpt3_200']\n",
        "gptj_names = ['augmented_gptj_10', 'augmented_gptj_50', 'augmented_gptj_100', 'augmented_gptj_200']\n",
        "gptneo_names = ['augmented_gptneo_10', 'augmented_gptneo_50', 'augmented_gptneo_100', 'augmented_gptneo_200']\n",
        "\n",
        "# define a dataframe for each LM\n",
        "df_baseline = df.loc[df['id'] == 'baseline']\n",
        "df_gpt3 = df.loc[df['id'].isin(gpt3_names)]\n",
        "df_gptj = df.loc[df['id'].isin(gptj_names)]\n",
        "df_gptneo = df.loc[df['id'].isin(gptneo_names)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICRTJSC6SzZD"
      },
      "source": [
        "We observe that the accuracy of the model increases as we augment more and more data. After generating 200 extra synthetic samples, the accuracy exceeds 70% indicating that text augmentation can greatly improve the accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp0rIiUl7dQb"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_curve(df, title):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "                        x=list(range(0, steps, 20)),\n",
        "                        y=pd.DataFrame(df_baseline.loc[0]['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                        name='accuracy {}'.format('baseline')))\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        \n",
        "        fig.add_trace(go.Scatter(\n",
        "                        x=list(range(0, steps, 20)),\n",
        "                        y=pd.DataFrame(row['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                        name='accuracy {}'.format(row['id'])))\n",
        "\n",
        "    fig.update_xaxes(title_text='step')\n",
        "    fig.update_yaxes(title_text='accuracy')\n",
        "    fig.update_layout(\n",
        "        title=title)\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xPlldKfg88KP",
        "outputId": "2aae733f-ee64-42c9-c0de-dca37430ff5a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"5633d30a-95aa-499a-80b8-2141791b9fbf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"5633d30a-95aa-499a-80b8-2141791b9fbf\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '5633d30a-95aa-499a-80b8-2141791b9fbf',\n",
              "                        [{\"name\": \"accuracy baseline\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.3324968632371393, 0.38017565872020076, 0.397741530740276, 0.4002509410288582, 0.4015056461731493, 0.4015056461731493]}, {\"name\": \"accuracy augmented_gpt3_10\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.4203262233375157, 0.5420326223337516, 0.5721455457967378, 0.5784190715181933, 0.5821831869510665, 0.5834378920953576, 0.5834378920953576]}, {\"name\": \"accuracy augmented_gpt3_50\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.4918444165621079, 0.5947302383939774, 0.5106649937264742, 0.5734002509410289, 0.5846925972396487, 0.5846925972396487]}, {\"name\": \"accuracy augmented_gpt3_100\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.26348808030112925, 0.7427854454203262, 0.8117942283563363, 0.6976160602258469, 0.616060225846926, 0.6612296110414053, 0.6637390213299874]}, {\"name\": \"accuracy augmented_gpt3_200\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.5181932245922208, 0.7590966122961104, 0.7089084065244667, 0.821831869510665, 0.7590966122961104, 0.7239648682559598, 0.71267252195734]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\"}, \"xaxis\": {\"title\": {\"text\": \"step\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5633d30a-95aa-499a-80b8-2141791b9fbf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_accuracy_curve(df_gpt3, \"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISMz0x0LCvJv"
      },
      "source": [
        "We observe that the accuracy of the model increases as we augment more and more data. After generating 200 extra synthetic samples, the accuracy exceeds 70% indicating that text augmentation can greatly improve the accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "9IEYdrC4nBIn",
        "outputId": "f7a0b80c-6e0e-4baa-854b-9a7b270cfa8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"e927fe24-64fd-44a5-900c-b5c556e69424\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"e927fe24-64fd-44a5-900c-b5c556e69424\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'e927fe24-64fd-44a5-900c-b5c556e69424',\n",
              "                        [{\"name\": \"accuracy baseline\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.3324968632371393, 0.38017565872020076, 0.397741530740276, 0.4002509410288582, 0.4015056461731493, 0.4015056461731493]}, {\"name\": \"accuracy augmented_gptneo_10\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.39021329987452946, 0.36386449184441655, 0.35131744040150564, 0.36386449184441655, 0.36762860727728985, 0.370138017565872, 0.370138017565872]}, {\"name\": \"accuracy augmented_gptneo_50\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.2120451693851945, 0.4353826850690088, 0.562107904642409, 0.5018820577164367, 0.6010037641154329, 0.5846925972396487, 0.5859473023839398]}, {\"name\": \"accuracy augmented_gptneo_100\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.06273525721455459, 0.2860727728983689, 0.26348808030112925, 0.33751568381430364, 0.4215809284818068, 0.3212045169385194, 0.3324968632371393]}, {\"name\": \"accuracy augmented_gptneo_200\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.06273525721455459, 0.07904642409033877, 0.27603513174404015, 0.21957340025094102, 0.48180677540777916, 0.39272271016311167, 0.39397741530740277]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-Neo).\"}, \"xaxis\": {\"title\": {\"text\": \"step\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e927fe24-64fd-44a5-900c-b5c556e69424');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_accuracy_curve(df_gptneo, \"Accuracy of the model in different versions of the dataset (augmentation by GPT-Neo).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXTnkEBOnBeO"
      },
      "source": [
        "The results of GPT-Neo are worse üòû. The performance of the model decreases when we generate synthetic data (except in the case of 50 synthetic samples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "iH90XkBgbcJj",
        "outputId": "0015d35d-b4e1-4bf2-e851-f3149c7b0a38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8e1a3658-a070-42e9-b100-8ab32dfbdd5d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8e1a3658-a070-42e9-b100-8ab32dfbdd5d\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8e1a3658-a070-42e9-b100-8ab32dfbdd5d',\n",
              "                        [{\"name\": \"accuracy baseline\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.3324968632371393, 0.38017565872020076, 0.397741530740276, 0.4002509410288582, 0.4015056461731493, 0.4015056461731493]}, {\"name\": \"accuracy augmented_gptj_10\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.5370138017565872, 0.5821831869510665, 0.4730238393977415, 0.5006273525721455, 0.5131744040150564, 0.5181932245922208, 0.5194479297365119]}, {\"name\": \"accuracy augmented_gptj_50\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.7841907151819323, 0.7867001254705144, 0.6775407779171895, 0.7189460476787954, 0.6248431618569636, 0.671267252195734, 0.6775407779171895]}, {\"name\": \"accuracy augmented_gptj_100\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.7214554579673776, 0.8055207026348808, 0.8042659974905897, 0.7653701380175659, 0.7478042659974906, 0.7565872020075283, 0.7603513174404015]}, {\"name\": \"accuracy augmented_gptj_200\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.6750313676286073, 0.8092848180677541, 0.823086574654956, 0.8469259723964868, 0.8644918444165621, 0.8569636135508155, 0.8569636135508155]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-J).\"}, \"xaxis\": {\"title\": {\"text\": \"step\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8e1a3658-a070-42e9-b100-8ab32dfbdd5d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_accuracy_curve(df_gptj, \"Accuracy of the model in different versions of the dataset (augmentation by GPT-J).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vhGv3G3TirU"
      },
      "source": [
        "The performance curve of GPT-J is awesome üéâ. Each time we increase the size of the train dataset with augmentation, there is a consistent increase in the accuracy reaching 85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjnV-ZHyCvMF"
      },
      "source": [
        "The next step is to investigate which language model boosts the final performance more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xHliv6hLd_y2",
        "outputId": "7c01d5bd-804e-4237-e903-76cfc3d2cbe8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"6ffdfb3e-f2c5-4272-9bee-47ee86126c57\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"6ffdfb3e-f2c5-4272-9bee-47ee86126c57\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '6ffdfb3e-f2c5-4272-9bee-47ee86126c57',\n",
              "                        [{\"name\": \"GPT-3\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200], \"y\": [0.4015056461731493, 0.5834378920953576, 0.5846925972396487, 0.6637390213299874, 0.71267252195734]}, {\"name\": \"GPT-J\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200], \"y\": [0.4015056461731493, 0.5194479297365119, 0.6775407779171895, 0.7603513174404015, 0.8569636135508155]}, {\"name\": \"GPT-Neo\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200], \"y\": [0.4015056461731493, 0.370138017565872, 0.5859473023839398, 0.3324968632371393, 0.39397741530740277]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Comparison of GPT-3, GPT-J and GPT-Neo in text augmentation.\"}, \"xaxis\": {\"title\": {\"text\": \"number of synthetic samples\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6ffdfb3e-f2c5-4272-9bee-47ee86126c57');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# keep the accuracy of the last training step\n",
        "acc_gpt3 = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(4):\n",
        "    acc_gpt3.append(df_gpt3.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "acc_gptj = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(4):\n",
        "    acc_gptj.append(df_gptj.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "acc_gptneo = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(4):\n",
        "    acc_gptneo.append(df_gptneo.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200],\n",
        "                y=acc_gpt3,\n",
        "                name='GPT-3'))\n",
        "\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200],\n",
        "                y=acc_gptj,\n",
        "                name='GPT-J'))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200],\n",
        "                y=acc_gptneo,\n",
        "                name='GPT-Neo'))\n",
        "\n",
        "fig.update_xaxes(title_text='number of synthetic samples')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(\n",
        "    title=\"Comparison of GPT-3, GPT-J and GPT-Neo in text augmentation.\")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3KM1Y0DC9l_"
      },
      "source": [
        "GPT-J outperforms GPT-3 in almost all different versions of the dataset üëè. These are very exciting results that indicate that we can use the open-source GPT-J instead of GPT-3 for augmentation. As for the GPT-Neo, it performs very poorly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49PkQsXLipqi"
      },
      "source": [
        "### Label Distribution\n",
        "\n",
        "It is interesting to examine how the distribution of the labels changes when we generate more and more synthetic samples. Our initial train set is balanced since it consists of 10 samples per class. Let's see how the distribution of the labels changes after text augmentation! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "B0Zv0UIqfM8Z",
        "outputId": "c3ce0276-19b1-4b79-80c3-148822ac13f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d5e80a47-4051-4ef6-81d4-dcb3c2f9adc4\" class=\"plotly-graph-div\" style=\"height:525px; width:1300px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d5e80a47-4051-4ef6-81d4-dcb3c2f9adc4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd5e80a47-4051-4ef6-81d4-dcb3c2f9adc4',\n",
              "                        [{\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\"], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"anger\", \"anger\"], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"surprise\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"anger\"], \"xaxis\": \"x3\", \"yaxis\": \"y3\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"surprise\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"anger\"], \"xaxis\": \"x4\", \"yaxis\": \"y4\"}],\n",
              "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Baseline (30 samples)\", \"x\": 0.10625, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"GPT-3 (200 synthetic samples)\", \"x\": 0.36875, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"GPT-Neo (200 synthetic samples)\", \"x\": 0.6312500000000001, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"GPT-J (200 synthetic samples)\", \"x\": 0.89375, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"bargap\": 0.3, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Distribution of labels\"}, \"width\": 1300, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2125]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.2625, 0.475]}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.525, 0.7375]}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7875, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0]}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.0, 1.0]}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d5e80a47-4051-4ef6-81d4-dcb3c2f9adc4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = make_subplots(rows=1, cols=4,\n",
        "                    subplot_titles=(\"Baseline (30 samples)\", \"GPT-3 (200 synthetic samples)\", \"GPT-Neo (200 synthetic samples)\", \"GPT-J (200 synthetic samples)\"))\n",
        "\n",
        "trace0 = go.Histogram(x=[mapping.int2str(i) for i in emotion_train_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace1 = go.Histogram(x=[mapping.int2str(i) for i in concatenate_datasets([emotion_train_ds, datasets_gpt3['200']])[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace2 = go.Histogram(x=[mapping.int2str(i) for i in concatenate_datasets([emotion_train_ds, datasets_gptneo['200']])[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace3 = go.Histogram(x=[mapping.int2str(i) for i in concatenate_datasets([emotion_train_ds, datasets_gptj['200']])[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig.append_trace(trace2, 1, 3)\n",
        "fig.append_trace(trace2, 1, 4)\n",
        "fig.update_layout(showlegend=False, title_text=\"Distribution of labels\", \n",
        "                  bargap=0.30, width=1300)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yutzoQDb0B4J"
      },
      "source": [
        "We observe that the distribution changes a lot and the large augmented dataset is highly imbalanced üòØ! GPT-3 model generated too many samples labeled as 'anger' while GPT-J and GPT-Neo generated more samples labeled as 'surprise'. The reason for this behavior is the datasets that these models are pre-trained on. GPT-J and GPT-Neo are trained on the same dataset and change the label distribution in a similar way.\n",
        "\n",
        "That's an interesting observation that we should further examine in the future! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCT49FJwzhB3"
      },
      "source": [
        "## ‚õè Generate more samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2tMLY7qI8SK"
      },
      "source": [
        "Text augmentation increased accuracy by a lot! The next step is to examine how much the accuracy improves when adding even more labelled samples. We expect that at some point, the accuracy curve stops increasing and stabilizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSTaVSOfiUOQ"
      },
      "outputs": [],
      "source": [
        "# load the synthetic datasets with 300, 400 and 500 samples.\n",
        "# run this if you do not want to generate new samples on your own.\n",
        "\n",
        "if not os.path.isdir('./data'):\n",
        "    !git clone https://github.com/ml6team/quick-tips.git\n",
        "    !cd quick-tips\n",
        "    !mv quick-tips/nlp/gpt3mix/data ./data\n",
        "    !rm -rf quick-tips\n",
        "\n",
        "synthetic_gpt3_300_ds = load_from_disk('./data/gpt-3/300')\n",
        "synthetic_gpt3_400_ds = load_from_disk('./data/gpt-3/400')\n",
        "synthetic_gpt3_500_ds = load_from_disk('./data/gpt-3/500')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5WBfDvpAP_F"
      },
      "outputs": [],
      "source": [
        "# prepare datasets\n",
        "max_size = 500\n",
        "steps = 5*int(max_size/batch_size) # 4 epochs in the large dataset\n",
        "\n",
        "datasets_gpt3_more = {'300': synthetic_gpt3_300_ds, '400': synthetic_gpt3_400_ds, '500': synthetic_gpt3_500_ds}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi2x-sI9CzO1"
      },
      "source": [
        "In case you loaded our results earlier, ignore the next cell that trains the model on the the new augmented datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIy1GV0vt7mk"
      },
      "outputs": [],
      "source": [
        "# train the model on the augmented datasets of GPT-3\n",
        "# in case you loaded our results earlier, ignore this cell\n",
        "\n",
        "for i in datasets_gpt3_more:\n",
        "    augmented_gpt3_ds = concatenate_datasets([emotion_train_ds, datasets_gpt3_more[i]])\n",
        "    metrics, logs = train_and_evaluate(augmented_gpt3_ds, emotion_test_ds, \"augmented_gpt3_\" + i)\n",
        "\n",
        "    run_dicts.append({\n",
        "        \"id\": \"augmented_gpt3_\" + i,\n",
        "        \"metrics\": metrics,\n",
        "        \"logs\": logs\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPWA5_9Cz5-7"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(run_dicts)\n",
        "gpt3_names_more = ['augmented_gpt3_10', 'augmented_gpt3_50', 'augmented_gpt3_100', 'augmented_gpt3_200', \n",
        "              'augmented_gpt3_300', 'augmented_gpt3_400', 'augmented_gpt3_500']\n",
        "\n",
        "df_gpt3_more = df.loc[df['id'].isin(gpt3_names_more)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "qur5SW4CmGeH",
        "outputId": "3fe63e36-ce9a-4502-911d-61266eaaa538"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"a67e927d-2662-45c3-8ced-a7c2c2813710\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"a67e927d-2662-45c3-8ced-a7c2c2813710\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'a67e927d-2662-45c3-8ced-a7c2c2813710',\n",
              "                        [{\"name\": \"GPT-3\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200, 300, 400, 500], \"y\": [0.4015056461731493, 0.5834378920953576, 0.5846925972396487, 0.6637390213299874, 0.71267252195734, 0.6900878293601004, 0.7189460476787954, 0.6386449184441656]}],\n",
              "                        {\"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\"}, \"xaxis\": {\"title\": {\"text\": \"number of extra samples\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a67e927d-2662-45c3-8ced-a7c2c2813710');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc_gpt3_more = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(7):\n",
        "    acc_gpt3_more.append(df_gpt3_more.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200, 300, 400, 500],\n",
        "                y=acc_gpt3_more,\n",
        "                name='GPT-3'))\n",
        "\n",
        "fig.update_xaxes(title_text='number of extra samples')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(showlegend=True, \n",
        "    title=\"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk_OM52qz-MV"
      },
      "source": [
        "The curve goes up really fast in the beginning but the increase gradually slows down the more samples we generate. So, we realise that there is a limit in the performance improvements that text augmentation can yield."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ALJ0WldXtrp"
      },
      "source": [
        "## üèÅ Take-aways \n",
        "\n",
        "\n",
        "You've reached the finish line! üëè  Let's summarize some of the findings.\n",
        "\n",
        "* We generated very realistic synthetic samples by leveraging the few-shot capabilities of large LMs and prompt engineering.\n",
        "* As a baseline, we trained a distilbert model on the Emotion dataset using a small subset of 30 samples.\n",
        "* Then, we augmented the small dataset with 10, 50, 100 and 200 extra samples generated by GPT-3, GPT-J and GPT-Neo.\n",
        "* We compared the performance of the models in all these settings and showed that data augmentation boosts the performance ü•≥.\n",
        "* We showed that GPT-J performs better than GPT-3 in our task and can be used as an open-source alternative for text augmentation üí™. GPT-Neo performs poorly mainly because it is much smaller.\n",
        "* However, the augmented datasets are not balanced anymore because large LMs are prone to generate samples with certain labels based on the data they are trained on.\n",
        "* Finally, as we generate more and more synthetic samples and the size of the training set increases, the overall performance increases until some point. Then, text augmentation cannot improve the performance more and we should look into other ways of increasing performance.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "nlp_gpt3mix.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
