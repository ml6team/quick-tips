{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_gpt3mix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b39348e38bfa4ff6a7266b023f0c58a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85d21cfd0acc41fcb3e9aca459820c7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f11d9c96a18b4ef0828de6b55ebf7fb9",
              "IPY_MODEL_5a5c40173f704c26bf4942d7217841d1",
              "IPY_MODEL_5ff00fca536c49e28bf6e8dce5a259a3"
            ]
          }
        },
        "85d21cfd0acc41fcb3e9aca459820c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f11d9c96a18b4ef0828de6b55ebf7fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84e282b8ef4646eab5df9f41c39a911d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c87bdfc339be47999ec49770d6ee67ec"
          }
        },
        "5a5c40173f704c26bf4942d7217841d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8134d4170465444c8b9965eb27bb3f28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac4431d9a3c9481dafe08955ea2b5217"
          }
        },
        "5ff00fca536c49e28bf6e8dce5a259a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_564be917b26d46889ca710db83a61a20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 55.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76417a8169554b359b889b3cbda96ebb"
          }
        },
        "84e282b8ef4646eab5df9f41c39a911d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c87bdfc339be47999ec49770d6ee67ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8134d4170465444c8b9965eb27bb3f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac4431d9a3c9481dafe08955ea2b5217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "564be917b26d46889ca710db83a61a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76417a8169554b359b889b3cbda96ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXro9efVU84k"
      },
      "source": [
        "# üìà: Text Augmentation using GPT-3\n",
        "\n",
        "This notebook looks into the possibility of performing data augmentation on an NLP dataset using the GPT-3 language model.\n",
        "\n",
        "Data augmentation techniques are used to generate additional samples. Data augmentation is already standard practice in computer vision projects üëå, but can also be leveraged in many NLP problems. We'll use a limited training set to simulate a real-world use case, where we often are constrained by the size of the available data ü§¶."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acwqGIAyU84m"
      },
      "source": [
        "## üõ†Ô∏è Getting started\n",
        "\n",
        "The cells below will setup everything that is required to get started with data augmentation and finetuning an NLP model with the HuggingFace API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIDjl_wU84m"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-ItvjqP4Cxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b549a9-2c36-4a22-abc9-154973fdb0d5"
      },
      "source": [
        "!!pip install -qq transformers datasets tokenizers openai requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir6zD__FU84n"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM-09Chsj7wI"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "from datasets import load_dataset, concatenate_datasets, load_from_disk, load_metric, Dataset\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, TrainerCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFQ6LEgjeRWb"
      },
      "source": [
        "### Download dataset\n",
        "We'll use [Emotion](https://huggingface.co/datasets/emotion) that is a dataset of English Twitter messages labeled as one of the six basic emotions: anger, fear, joy, love, sadness and surprise. To make our task a bit easier, we will use only three of them, namely:\n",
        "- joy üòÇ\n",
        "- anger üò†\n",
        "- surprise üòØ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ltsurmvaaGd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "b39348e38bfa4ff6a7266b023f0c58a8",
            "85d21cfd0acc41fcb3e9aca459820c7a",
            "f11d9c96a18b4ef0828de6b55ebf7fb9",
            "5a5c40173f704c26bf4942d7217841d1",
            "5ff00fca536c49e28bf6e8dce5a259a3",
            "84e282b8ef4646eab5df9f41c39a911d",
            "c87bdfc339be47999ec49770d6ee67ec",
            "8134d4170465444c8b9965eb27bb3f28",
            "ac4431d9a3c9481dafe08955ea2b5217",
            "564be917b26d46889ca710db83a61a20",
            "76417a8169554b359b889b3cbda96ebb"
          ]
        },
        "outputId": "fdb8b35d-b298-4a9b-9410-1fd6db991bdb"
      },
      "source": [
        "# load the dataset and filter on samples that have a token count less than 30 to use only short tweets\n",
        "max_input_len = 30\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
        "emotion_ds = load_dataset(\"emotion\").filter(lambda e: len(tokenizer.batch_encode_plus([e['text']]).input_ids[0]) < int(max_input_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset emotion (/root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b39348e38bfa4ff6a7266b023f0c58a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-7161aca97360dca6.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-51b5751515a95f0f.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-3ad9ee5140e9d78b.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ24-mWS6elF"
      },
      "source": [
        "The dataset is already split into 16,000 train, 2,000 validation and 2,000 test samples. To investigate the effectiveness of the GPT3Mix augmentation method, we will use only 10 samples per class as a train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YI6-pZdSqnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d03419-bc4b-4f5c-ca74-3c4ebe633043"
      },
      "source": [
        "# select 10 random train samples from each of the three emotions\n",
        "# sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5)\n",
        "joy_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 1).select(range(10))\n",
        "anger_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 3).select(range(10))\n",
        "surprise_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 5).select(range(10))\n",
        "\n",
        "# map emotions to integers for labeling\n",
        "# joy (0), anger (1), surprise (2)\n",
        "def map_emotions(example):\n",
        "  example['label'] = example['label']//2\n",
        "  return example\n",
        "\n",
        "# create a train set that consists of 10 samples per class and filter the test \n",
        "# set to contain only the valid labels\n",
        "emotion_train_ds = concatenate_datasets([joy_train_samples, anger_train_samples, surprise_train_samples]).map(lambda e: map_emotions(e)).shuffle(seed=42)\n",
        "emotion_test_ds = emotion_ds[\"test\"].filter(lambda e: e['label'] in [1, 3, 5]).map(lambda e: map_emotions(e))\n",
        "\n",
        "# define the maping between emotions and labels\n",
        "idx2label = {0: 'joy', 1: 'anger', 2: 'surprise'}\n",
        "label2idx = {'joy': 0, 'anger': 1, 'surprise': 2}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-e3bce96661aef73f.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-0ff5c2cf14824a2f.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-08f457529a6b90e7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-17c71e67601da363.arrow\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-9af892442dfd8f9c.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-b17905676460b0ef.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-533ce78997a9f97c.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi2XjbC69Of5"
      },
      "source": [
        "Before proceeding with the data augmentation, let's have a look into the baseline dataset üòé!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD2xmdrg9OLY",
        "outputId": "57e36e5a-8aba-4223-e65d-2c72ad69c5bf"
      },
      "source": [
        "print(\"Train set\")\n",
        "print(\"Total samples: {}\\n\".format(len(emotion_train_ds)))\n",
        "print(\"A random sample\")\n",
        "print(\"Text: {} \\nLabel: {}\".format(emotion_train_ds['text'][10], idx2label[emotion_train_ds['label'][10]]))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Test set\")\n",
        "print(\"Total samples: {}\\n\".format(len(emotion_test_ds)))\n",
        "print(\"A random sample\")\n",
        "print(\"Text: {} \\nLabel: {}\".format(emotion_test_ds['text'][10], idx2label[emotion_test_ds['label'][10]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set\n",
            "Total samples: 30\n",
            "\n",
            "A random sample\n",
            "Text: i feel angered and firey \n",
            "Label: anger\n",
            "\n",
            "\n",
            "Test set\n",
            "Total samples: 775\n",
            "\n",
            "A random sample\n",
            "Text: im feeling very peaceful about our wedding again now after having \n",
            "Label: joy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIJPd8P9S9kW"
      },
      "source": [
        "## GPT3Mix pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkx02t5Z3ZVN"
      },
      "source": [
        "We will use [GPT3Mix](https://arxiv.org/abs/2104.08826) model to generate synthetic but hyper-realistic samples from a mixture of real saples utilizing the [GPT-3](https://arxiv.org/abs/2005.14165) language model. Specifically, GPT3Mix takes two real samples from our dataset, embeds these samples in a carefully designed prompt and generates an augmented mixed sample influenced by the sample sentences.\n",
        "\n",
        "\n",
        "Generallly, a GPT3Mix prompt looks like this:\n",
        "\n",
        "    Each item in the following list contains a <text type> and the\n",
        "    respective <label type>. <label type> is one of ‚Äô<label token 1>‚Äô,\n",
        "    ..., or ‚Äô<label token N>‚Äô. \n",
        "    <text type>: <example text 1> (<label type>: <example label 1>)\n",
        "    ...\n",
        "    <text type>: <example text k> (<label type>: <example label k>)\n",
        "    <text type>:\n",
        "\n",
        "In our case the prompt looks like this:\n",
        "\n",
        "    Each item in the following list contains a tweet and the\n",
        "    respective sentiment. Sentiment is one of ‚Äôjoy‚Äô, 'surprise' or 'anger'. \n",
        "    Tweet: i feel angered and firey (Sentiment: anger)\n",
        "    Tweet: im feeling very peaceful about our wedding again now after having (Sentiment: joy)\n",
        "    Tweet:\n",
        "\n",
        "You can find more information on how GPT3Mix augmentation method works in the [paper](https://arxiv.org/abs/2104.08826)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj2Of7vGILFJ"
      },
      "source": [
        "First, we should extract pairs of samples from the train set. There are various extraction strategies that can be used to increase the quality of the synthetic samples. We will simply extract the pairs randomly since by repeating random sampling a diverse synthetic dataset will be created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlI7GYwbGx5m"
      },
      "source": [
        "# define a function that returns two random samples from the train set.\n",
        "def get_random_samples():\n",
        "  s1 = random.randint(0, len(emotion_train_ds)-1)\n",
        "  s2 = random.randint(0, len(emotion_train_ds)-1)\n",
        "  return emotion_train_ds['text'][s1], emotion_train_ds['label'][s1], emotion_train_ds['text'][s2], emotion_train_ds['label'][s2]\n",
        "\n",
        "# define a function that takes as input two samples and generates the prompt\n",
        "# that we should pass to the GPT-3 language model for completion.\n",
        "def get_prompt(text1, label1, text2, label2):\n",
        "  description = \"Each item in the following list contains a tweet and the respective sentiment. Sentiment is one of 'joy', 'surprise' or 'anger'.\"\n",
        "  prompt = (f\"{description}\\n\"\n",
        "            f\"Tweet: {text1} (Sentiment: {idx2label[label1]})\\n\"\n",
        "            f\"Tweet: {text2} (Sentiment: {idx2label[label2]})\\n\"\n",
        "            f\"Tweet:\")\n",
        "  return prompt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAzLn9t83YCS"
      },
      "source": [
        "# define the number of synthetic samples to generate\n",
        "n = 10\n",
        "new_texts = []\n",
        "new_labels = []\n",
        "api_key =  # insert your api key for GPT-3\n",
        "headers = {'Authorization' : 'Bearer ' + api_key ,\n",
        "              'Content-type':'application/json', \n",
        "              'Accept':'application/json'}\n",
        "\n",
        "iter = 0\n",
        "while iter < n:\n",
        "  # select two random samples from training set\n",
        "  text1, label1, text2, label2 = get_random_samples()\n",
        "  # create the prompt\n",
        "  prompt = get_prompt(text1, label1, text2, label2)\n",
        "  # send a post request to gpt-3 using the prompt\n",
        "  response = requests.post('https://api.openai.com/v1/engines/davinci/completions', \n",
        "                           headers=headers,\n",
        "                           data = json.dumps({\"prompt\": prompt, \n",
        "                                              \"max_tokens\": 30,\n",
        "                                              \"temperature\": 0.9,\n",
        "                                              \"top_p\": 0.95}))\n",
        "\n",
        "  # get response and extract the generated text and label\n",
        "  # the generated output will be in the form \"<text> (Sentiment: <label>)\"\n",
        "  data = response.json()['choices'][0]['text'].split('\\n')[0].split('(Sentiment:')\n",
        "\n",
        "  if len(data) < 2:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "\n",
        "  text = data[0]\n",
        "  label = data[1].split(')')[0].strip()\n",
        "\n",
        "  if label not in ['joy', 'anger', 'surprise']:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "\n",
        "  new_texts.append(text)\n",
        "  new_labels.append(label2idx[label])\n",
        "  iter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nqie0c2Suc3"
      },
      "source": [
        "We will generate 3 synthetic datasets (10, 50 and 100 extra samples) in order to examine how the size of the dataset influences the model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2CXeyLHCKkT"
      },
      "source": [
        "# define the synthetic dataset and save it to disk so as to prevent sending \n",
        "# many api requests\n",
        "synthetic_ds = Dataset.from_dict({'text': new_texts, 'label': new_labels})\n",
        "\n",
        "synthetic_ds.save_to_disk('./synthetic_dataset_10')\n",
        "# synthetic_ds.save_to_disk('./synthetic_dataset_50')\n",
        "# synthetic_ds.save_to_disk('./synthetic_dataset_100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoUeViJAISKP"
      },
      "source": [
        "Now let's see some synthetic data to examine their quality!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPlF7dXKor6v"
      },
      "source": [
        "# load the synthetic datasets with 10, 50 and 100 samples\n",
        "# run this if the dataset has already been saved set the path in your workspace\n",
        "synthetic_10_ds = load_from_disk('./drive/MyDrive/gpt3mix_synthetic_data/synthetic_dataset_10')\n",
        "synthetic_50_ds = load_from_disk('./drive/MyDrive/gpt3mix_synthetic_data/synthetic_dataset_50')\n",
        "synthetic_100_ds = load_from_disk('./drive/MyDrive/gpt3mix_synthetic_data/synthetic_dataset_100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6irrOSPrKVU9",
        "outputId": "80e780d4-3d55-402e-877f-c88650b028ea"
      },
      "source": [
        "print(\"Text: {} \\nLabel: {}\".format(synthetic_10_ds['text'][5], idx2label[synthetic_10_ds['label'][5]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  even if ur not into these kind of things u have to admit it's pretty cool  \n",
            "Label: joy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiofN18bKZ0f",
        "outputId": "4f0d716c-49c2-48f7-8a27-cab0daf0077e"
      },
      "source": [
        "print(\"Text: {} \\nLabel: {}\".format(synthetic_50_ds['text'][5], idx2label[synthetic_50_ds['label'][5]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  i want to stop running and walk...but the fact that i'm still running is the real miracle  \n",
            "Label: joy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpwH-elSKaKh",
        "outputId": "577b2b0f-f04f-40ea-ffe1-4e268df03bf1"
      },
      "source": [
        "print(\"Text: {} \\nLabel: {}\".format(synthetic_100_ds['text'][5], idx2label[synthetic_100_ds['label'][5]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  i want a beer right now  \n",
            "Label: anger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6dLc7xMK0NJ"
      },
      "source": [
        "We see that GPT-3 has effectively generated very realistic samples. üëèüëèüëè"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gesWuhM9jbLq"
      },
      "source": [
        "## üöÄ Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QaSNzfSTG4D"
      },
      "source": [
        "Here we define the model and the training pipeline. We will use [DistilBERT](https://arxiv.org/abs/1910.01108) that is a light Transformer trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT‚Äôs performances as measured on the GLUE language understanding benchmark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xqcEiJqBZsB"
      },
      "source": [
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "batch_size = 6\n",
        "epochs = 20\n",
        "\n",
        "run_dicts = [] # list of dicts to store both metrics and logs for all the experiment runs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-q6U8DAx0Jp"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "        Calculates the accuracy of the model's predictions, calculated as follows; (TP + TN) / (TP + TN + FP + FN) with TP: True positive TN: True negative FP: False positive FN: False negative\n",
        "    \"\"\"\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels) \n",
        "\n",
        "\n",
        "class LogAccumulatorCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    A class that stores both the training and the evaluation loss\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.acc_logs = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero and ('loss' in logs or 'eval_loss' in logs):\n",
        "            self.acc_logs.append(logs.copy())\n",
        "\n",
        "\n",
        "def train_and_evaluate(train_ds, test_ds, identifier):\n",
        "    def tokenize(batch):\n",
        "        return tokenizer(batch['text'], padding=True, truncation=True)\n",
        "    \n",
        "    train_ds = train_ds.map(tokenize, batched=True, batch_size=len(train_ds), remove_columns=[\"text\"])\n",
        "    test_ds = test_ds.map(tokenize, batched=True, batch_size=len(test_ds), remove_columns=[\"text\"])\n",
        "    \n",
        "    training_args = TrainingArguments(\n",
        "        identifier,\n",
        "        num_train_epochs=epochs,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        logging_strategy=\"epoch\",\n",
        "        weight_decay=0.01,\n",
        "        learning_rate=2e-5,\n",
        "    )\n",
        "    \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-cased\", num_labels=3)\n",
        "\n",
        "    # Partially freezing the weights of initial layers of the model\n",
        "    # Since we're working on small datasets as it usually reduces overfitting\n",
        "    # Another advantage of partial freezing is reduced memory usage and a speed improvement during training.\n",
        "    for block in model.distilbert.embeddings.modules():\n",
        "        for param in block.parameters():\n",
        "            param.requires_grad=False\n",
        "\n",
        "    for i in [0,1,2]:\n",
        "        for block in model.distilbert.transformer.layer[i].modules():\n",
        "            for param in block.parameters():\n",
        "                param.requires_grad=False\n",
        "\n",
        "            \n",
        "    logger = LogAccumulatorCallback()\n",
        "    trainer = Trainer(\n",
        "        model=model, args=training_args, \n",
        "        train_dataset=train_ds, \n",
        "        eval_dataset=test_ds,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[logger],\n",
        "    )\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    \n",
        "    return metrics, logger.acc_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIp57un2x7Qy",
        "outputId": "9254321f-4eb6-4cca-88d8-db0b6776db97"
      },
      "source": [
        "### Model baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5mDmH_lwU84r",
        "outputId": "a2974598-512f-45a1-e318-0a7d62ad9c98"
      },
      "source": [
        "# train our model on the baseline dataset without augmentation\n",
        "metrics, logs = train_and_evaluate(emotion_train_ds, emotion_test_ds, \"baseline\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"baseline\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-fe012414826d71c9.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-240db4f8c3d82b2c.arrow\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 30\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 6\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 100\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:55, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.103100</td>\n",
              "      <td>1.189810</td>\n",
              "      <td>0.063226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.097800</td>\n",
              "      <td>1.172908</td>\n",
              "      <td>0.129032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.079600</td>\n",
              "      <td>1.164873</td>\n",
              "      <td>0.144516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.062300</td>\n",
              "      <td>1.150708</td>\n",
              "      <td>0.150968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.050300</td>\n",
              "      <td>1.131751</td>\n",
              "      <td>0.179355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.002900</td>\n",
              "      <td>1.128905</td>\n",
              "      <td>0.198710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.021200</td>\n",
              "      <td>1.122984</td>\n",
              "      <td>0.255484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.955800</td>\n",
              "      <td>1.127501</td>\n",
              "      <td>0.269677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.909200</td>\n",
              "      <td>1.109547</td>\n",
              "      <td>0.322581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.874500</td>\n",
              "      <td>1.101225</td>\n",
              "      <td>0.347097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.793400</td>\n",
              "      <td>1.090336</td>\n",
              "      <td>0.347097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>1.081771</td>\n",
              "      <td>0.365161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.694600</td>\n",
              "      <td>1.064120</td>\n",
              "      <td>0.383226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.638000</td>\n",
              "      <td>1.062106</td>\n",
              "      <td>0.390968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.569900</td>\n",
              "      <td>1.050431</td>\n",
              "      <td>0.405161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.525900</td>\n",
              "      <td>1.043916</td>\n",
              "      <td>0.411613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.483700</td>\n",
              "      <td>1.026753</td>\n",
              "      <td>0.429677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.461700</td>\n",
              "      <td>1.017546</td>\n",
              "      <td>0.438710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.462100</td>\n",
              "      <td>1.016237</td>\n",
              "      <td>0.443871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.448200</td>\n",
              "      <td>1.015804</td>\n",
              "      <td>0.443871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jge5A7tfo5Qp"
      },
      "source": [
        "### Model with augmented data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4zpt0ZyDU84s",
        "outputId": "8a5e4641-1f54-45dc-d290-a2796883e21e"
      },
      "source": [
        "# train our model on the augmented dataset that contains 10 extra synthetic samples.\n",
        "augmented_10_train_ds = concatenate_datasets([emotion_train_ds, synthetic_10_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_10_train_ds, emotion_test_ds, \"augmented_10\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_10\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-6f7599790f6222ce.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-240db4f8c3d82b2c.arrow\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 40\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 6\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 140\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 00:58, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.102700</td>\n",
              "      <td>1.169440</td>\n",
              "      <td>0.063226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.101000</td>\n",
              "      <td>1.163339</td>\n",
              "      <td>0.065806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.091500</td>\n",
              "      <td>1.136249</td>\n",
              "      <td>0.183226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.055800</td>\n",
              "      <td>1.120108</td>\n",
              "      <td>0.183226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.023700</td>\n",
              "      <td>1.112106</td>\n",
              "      <td>0.267097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.998000</td>\n",
              "      <td>1.098689</td>\n",
              "      <td>0.332903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.937800</td>\n",
              "      <td>1.075746</td>\n",
              "      <td>0.427097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.889700</td>\n",
              "      <td>1.054886</td>\n",
              "      <td>0.454194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.829300</td>\n",
              "      <td>1.042476</td>\n",
              "      <td>0.464516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.704400</td>\n",
              "      <td>1.023852</td>\n",
              "      <td>0.464516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.613100</td>\n",
              "      <td>1.031081</td>\n",
              "      <td>0.463226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.546900</td>\n",
              "      <td>1.040900</td>\n",
              "      <td>0.436129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.486400</td>\n",
              "      <td>1.009155</td>\n",
              "      <td>0.473548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.421300</td>\n",
              "      <td>0.984990</td>\n",
              "      <td>0.483871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.401600</td>\n",
              "      <td>0.993147</td>\n",
              "      <td>0.482581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.330200</td>\n",
              "      <td>0.971744</td>\n",
              "      <td>0.492903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.310300</td>\n",
              "      <td>0.980922</td>\n",
              "      <td>0.487742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.275100</td>\n",
              "      <td>0.984452</td>\n",
              "      <td>0.486452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.277300</td>\n",
              "      <td>0.981821</td>\n",
              "      <td>0.489032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.265200</td>\n",
              "      <td>0.985143</td>\n",
              "      <td>0.487742</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uD2fNj8kNa_t",
        "outputId": "e8ddcd41-116f-43d2-d2c4-9475c1372e15"
      },
      "source": [
        "# train our model on the augmented dataset that contains 50 extra synthetic samples.\n",
        "augmented_50_train_ds = concatenate_datasets([emotion_train_ds, synthetic_50_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_50_train_ds, emotion_test_ds, \"augmented_50\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_50\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-cf85caccfd981ecb.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-240db4f8c3d82b2c.arrow\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 80\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 6\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 280\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [280/280 01:04, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.121100</td>\n",
              "      <td>1.146652</td>\n",
              "      <td>0.261935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.105300</td>\n",
              "      <td>1.092461</td>\n",
              "      <td>0.261935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.056200</td>\n",
              "      <td>1.042968</td>\n",
              "      <td>0.261935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.054100</td>\n",
              "      <td>1.065799</td>\n",
              "      <td>0.265806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.972200</td>\n",
              "      <td>1.085281</td>\n",
              "      <td>0.357419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.866000</td>\n",
              "      <td>1.055105</td>\n",
              "      <td>0.474839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.738200</td>\n",
              "      <td>0.986825</td>\n",
              "      <td>0.565161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.624300</td>\n",
              "      <td>1.053603</td>\n",
              "      <td>0.473548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.496200</td>\n",
              "      <td>0.880032</td>\n",
              "      <td>0.609032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.411200</td>\n",
              "      <td>0.989683</td>\n",
              "      <td>0.549677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.324800</td>\n",
              "      <td>0.981255</td>\n",
              "      <td>0.565161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.253900</td>\n",
              "      <td>0.985126</td>\n",
              "      <td>0.547097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.217200</td>\n",
              "      <td>1.072494</td>\n",
              "      <td>0.544516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.155000</td>\n",
              "      <td>1.074408</td>\n",
              "      <td>0.556129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.121700</td>\n",
              "      <td>1.133451</td>\n",
              "      <td>0.530323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.098300</td>\n",
              "      <td>1.108648</td>\n",
              "      <td>0.552258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.078800</td>\n",
              "      <td>1.223875</td>\n",
              "      <td>0.523871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.076000</td>\n",
              "      <td>1.233928</td>\n",
              "      <td>0.526452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.063300</td>\n",
              "      <td>1.194352</td>\n",
              "      <td>0.543226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.066200</td>\n",
              "      <td>1.200891</td>\n",
              "      <td>0.541935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i8wBLo-6NbOf",
        "outputId": "74458beb-d17e-4e54-a8c9-be92d719d922"
      },
      "source": [
        "# train our model on the augmented dataset that contains 100 extra synthetic samples.\n",
        "augmented_100_train_ds = concatenate_datasets([emotion_train_ds, synthetic_100_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_100_train_ds, emotion_test_ds, \"augmented_100\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_100\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-02f3d16a92bee602.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-240db4f8c3d82b2c.arrow\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 130\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 6\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 440\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [440/440 01:12, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.053000</td>\n",
              "      <td>1.119105</td>\n",
              "      <td>0.261935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.022800</td>\n",
              "      <td>1.233681</td>\n",
              "      <td>0.261935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.978100</td>\n",
              "      <td>1.117986</td>\n",
              "      <td>0.261935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.878300</td>\n",
              "      <td>0.878676</td>\n",
              "      <td>0.745806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.691200</td>\n",
              "      <td>0.850739</td>\n",
              "      <td>0.690323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.511600</td>\n",
              "      <td>0.746332</td>\n",
              "      <td>0.758710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.386600</td>\n",
              "      <td>0.657123</td>\n",
              "      <td>0.796129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.306100</td>\n",
              "      <td>0.680348</td>\n",
              "      <td>0.748387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.263800</td>\n",
              "      <td>0.940879</td>\n",
              "      <td>0.656774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.182900</td>\n",
              "      <td>0.825558</td>\n",
              "      <td>0.682581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.120100</td>\n",
              "      <td>0.871154</td>\n",
              "      <td>0.700645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.932700</td>\n",
              "      <td>0.658065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.048300</td>\n",
              "      <td>0.881228</td>\n",
              "      <td>0.710968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.040600</td>\n",
              "      <td>0.979125</td>\n",
              "      <td>0.683871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.024800</td>\n",
              "      <td>1.010552</td>\n",
              "      <td>0.687742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.019600</td>\n",
              "      <td>0.978896</td>\n",
              "      <td>0.690323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>1.020801</td>\n",
              "      <td>0.683871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.013600</td>\n",
              "      <td>0.970726</td>\n",
              "      <td>0.707097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.013700</td>\n",
              "      <td>0.994469</td>\n",
              "      <td>0.703226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.014700</td>\n",
              "      <td>0.994133</td>\n",
              "      <td>0.704516</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 775\n",
            "  Batch size = 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TKTBiKUU84t"
      },
      "source": [
        "##  üìä Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3itfEYbTU84t"
      },
      "source": [
        "df = pd.DataFrame(run_dicts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl7lOBjjTjGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "b9505a4e-352f-4cf7-9676-4c86b2fa54be"
      },
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "                    x=list(range(n)),\n",
        "                    y=pd.DataFrame(row['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                    name='accuracy {}'.format(row['id'])))\n",
        "\n",
        "fig.update_xaxes(title_text='epoch')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ba1fdaba-ddf0-4e72-b999-2886121d18d9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ba1fdaba-ddf0-4e72-b999-2886121d18d9\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ba1fdaba-ddf0-4e72-b999-2886121d18d9',\n",
              "                        [{\"name\": \"accuracy baseline\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.06322580645161291, 0.12903225806451613, 0.14451612903225808, 0.15096774193548387, 0.17935483870967742, 0.19870967741935483, 0.25548387096774194, 0.2696774193548387, 0.3225806451612903, 0.3470967741935484, 0.3470967741935484, 0.36516129032258066, 0.3832258064516129, 0.3909677419354839, 0.40516129032258064, 0.41161290322580646, 0.4296774193548387, 0.43870967741935485, 0.44387096774193546, 0.44387096774193546, 0.44387096774193546]}, {\"name\": \"accuracy augmented_10\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.06322580645161291, 0.06580645161290323, 0.1832258064516129, 0.1832258064516129, 0.2670967741935484, 0.3329032258064516, 0.4270967741935484, 0.4541935483870968, 0.4645161290322581, 0.4645161290322581, 0.4632258064516129, 0.43612903225806454, 0.4735483870967742, 0.4838709677419355, 0.48258064516129034, 0.49290322580645163, 0.48774193548387096, 0.4864516129032258, 0.4890322580645161, 0.48774193548387096, 0.48774193548387096]}, {\"name\": \"accuracy augmented_50\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.26193548387096777, 0.26193548387096777, 0.26193548387096777, 0.2658064516129032, 0.3574193548387097, 0.47483870967741937, 0.5651612903225807, 0.4735483870967742, 0.6090322580645161, 0.5496774193548387, 0.5651612903225807, 0.5470967741935484, 0.5445161290322581, 0.5561290322580645, 0.5303225806451612, 0.552258064516129, 0.5238709677419355, 0.5264516129032258, 0.5432258064516129, 0.5419354838709678, 0.5419354838709678]}, {\"name\": \"accuracy augmented_100\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.26193548387096777, 0.26193548387096777, 0.26193548387096777, 0.7458064516129033, 0.6903225806451613, 0.7587096774193548, 0.7961290322580645, 0.7483870967741936, 0.6567741935483871, 0.6825806451612904, 0.7006451612903226, 0.6580645161290323, 0.7109677419354838, 0.6838709677419355, 0.687741935483871, 0.6903225806451613, 0.6838709677419355, 0.7070967741935484, 0.7032258064516129, 0.704516129032258, 0.704516129032258]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ba1fdaba-ddf0-4e72-b999-2886121d18d9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gW8s4OvZBlX"
      },
      "source": [
        "Our initial train set is balanced since it consists of 10 samples per class. Let's see how the distribution of the labels changes after the random sapling method for extracting pairs and the GPT3Mix augmentation technique! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "HkV9CEIYaOrD",
        "outputId": "ff447a5c-6ca5-4443-ad80-ec38a3edce5b"
      },
      "source": [
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig = make_subplots(rows=2, cols=2,\n",
        "                    subplot_titles=(\"Baseline\", \"Augmented-10\", \"Augmented-50\", \"Augmented-100\"))\n",
        "\n",
        "trace0 = go.Histogram(x=[idx2label[i] for i in emotion_train_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace1 = go.Histogram(x=[idx2label[i] for i in augmented_10_train_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace2 = go.Histogram(x=[idx2label[i] for i in augmented_50_train_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace3 = go.Histogram(x=[idx2label[i] for i in augmented_100_train_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig.append_trace(trace2, 2, 1)\n",
        "fig.append_trace(trace3, 2, 2)\n",
        "fig.update_layout(showlegend=False, title_text=\"Distribution of labels\", \n",
        "                  bargap=0.30)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"022c49a4-e7ae-4c13-a315-d3a8fcdcd20b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"022c49a4-e7ae-4c13-a315-d3a8fcdcd20b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '022c49a4-e7ae-4c13-a315-d3a8fcdcd20b',\n",
              "                        [{\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\"], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\"], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"surprise\", \"anger\", \"anger\", \"joy\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"joy\"], \"xaxis\": \"x3\", \"yaxis\": \"y3\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"anger\", \"anger\", \"joy\", \"surprise\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"surprise\", \"anger\", \"joy\"], \"xaxis\": \"x4\", \"yaxis\": \"y4\"}],\n",
              "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Baseline\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Augmented-10\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Augmented-50\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Augmented-100\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"bargap\": 0.3, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Distribution of labels\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.0, 0.45]}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.55, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.625, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 0.375]}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.0, 0.375]}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('022c49a4-e7ae-4c13-a315-d3a8fcdcd20b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB90J5FrvVXD"
      },
      "source": [
        "We observe that the distribution changes a lot and the large augmented dataset is highly imbalanced! GPT-3 model generated too many samples labeled as 'anger' while ideally we want to generate a balanced train set.\n",
        "\n",
        "That's an interesting observation that we should further examine in the future üòØ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ALJ0WldXtrp"
      },
      "source": [
        "## üèÅ Take-aways \n",
        "\n",
        "\n",
        "You've reached the finish line! üëè  Let's sum up some of the findings.\n",
        "\n",
        "* We managed to generate hyper-realistic synthetic samples using GPT3Mix indicating that we can use it as a text augmentation technique.\n",
        "* As a baseline, we trained a distilbert model on the Emotion dataset using a small subset of 30 samples.\n",
        "* Then we augmented the small dataset with 10, 50 and 100 extra samples generated by GPT-3.\n",
        "* We compared the performance of the models in all these settings and showed that data augmentation boosts the performance.\n",
        "* As we generate more and more synthetic samples and the size of the training set increases, the overall performance increases too.\n",
        "* However, the augmented datasets are not balanced anymore because GPT-3 was more prone to generate 'anger' samples.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}