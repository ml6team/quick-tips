{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pke_keyword_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E5fga3OkHom-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne2ic1nmhs0n"
      },
      "source": [
        "# Tip of the week: \"The KEYNG (read *king*) is dead, long live the KEYNG!\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvXj0fPGMXX9"
      },
      "source": [
        "For a long time the go-to library for graph-based keyword extraction has been Gensim. However, [version 4.0.0](https://github.com/RaRe-Technologies/gensim/releases)‚Äîwhich was *just* released and provides amazing performance improvements‚Äî[removed the entire summarisation module](https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4#12-removed-gensimsummarization), which includes the keyword extraction functionality.\n",
        "\n",
        "This motivates an update on **keyword extraction** from a previous Tip of the week on extractive summarization which included a section about keyword extraction with Gensim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQN6D4QVB2vM"
      },
      "source": [
        "This notebook gives a brief overview of **pke** an **open-source keyphrase extraction toolkit**, that is easy to use, provides a wide range of keyword extraction methods which makes it easy to benchmark different approaches in order to choose the right algorithm for the problem at hand.\n",
        "\n",
        "In contrast to Gensim, which only provided keyword extraction using the widely known TextRank algorithm, `pke` offers [statistical models](https://boudinfl.github.io/pke/build/html/unsupervised.html#statistical-models), a [variety of TextRank flavours](https://boudinfl.github.io/pke/build/html/unsupervised.html#graph-based-models), as well as [simple supervised methods](https://boudinfl.github.io/pke/build/html/supervised.html) which even come pre-trained.\n",
        "\n",
        "In `pke` **preprocessing is built-in** using **spaCy**. This means the times of tormenting non-English languages with numerous preprocessing steps in order to make it look like English are finally over. *Bon vent !*\n",
        "\n",
        "Follow the code in this notebook to see how to use `pke` to extract keywords and a comparison of the extracted keywords.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5fga3OkHom-"
      },
      "source": [
        "## üèó Getting started: Install packages & download models\n",
        "\n",
        "The below cells will set up everything that is required to get started with keyword extraction:\n",
        "\n",
        "* Install packages\n",
        "* Download additional resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbWP_PcNsL8Q"
      },
      "source": [
        "# Install pke\n",
        "!pip install --quiet git+https://github.com/boudinfl/pke.git\n",
        "\n",
        "# Download additional resources\n",
        "!python -m nltk.downloader stopwords\n",
        "!python -m nltk.downloader universal_tagset\n",
        "!python -m spacy download en # Download English model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSSEhYB2ICDh"
      },
      "source": [
        "## üß∞ Keyword Extraction using pke\n",
        "\n",
        "`pke` provides implementations of the following keyword extraction algorithms:\n",
        "\n",
        "* Statistical models:\n",
        "    * TF‚ÄìIDF\n",
        "    * KPMiner\n",
        "    * YAKE\n",
        "* Graph-based models:\n",
        "    * TextRank\n",
        "    * SingleRank\n",
        "    * TopicRank\n",
        "    * TopicalPageRank\n",
        "    * PositionRank\n",
        "    * MultipartiteRank\n",
        "* Supervised models\n",
        "    * Kea\n",
        "    * WINGNUS\n",
        "\n",
        "The code below wraps several of these extraction methods into convenience functions that use the default parameters and only require an (English) text from which keywords will be extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH1giKSaU4-6"
      },
      "source": [
        "import string\n",
        "from itertools import zip_longest\n",
        "\n",
        "import pke\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Convenience functions for pke keyword extraction\n",
        "\n",
        "## Supervised models\n",
        "def extract_kea_keywords(text, top_n=10, language='en', normalization=None, \n",
        "                         only_keywords=True):\n",
        "    stoplist = stopwords.words('english')\n",
        "    extractor = pke.supervised.Kea()\n",
        "    extractor.load_document(input=text, language=language, normalization=normalization)\n",
        "    extractor.candidate_selection(stoplist=stoplist)\n",
        "    extractor.candidate_weighting()\n",
        "    keyphrases = extractor.get_n_best(n=top_n)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases\n",
        "\n",
        "## Statistical models\n",
        "def extract_tfidf_keywords(text, top_n=10, language='en', normalization=None, \n",
        "                           n_grams=3, only_keywords=True):\n",
        "    stoplist = list(string.punctuation)\n",
        "    stoplist += stopwords.words('english')\n",
        "    extractor = pke.unsupervised.TfIdf()\n",
        "    extractor.load_document(input=text, language=language, normalization=normalization)\n",
        "    extractor.candidate_selection(n=n_grams, stoplist=stoplist)\n",
        "    extractor.candidate_weighting()\n",
        "    keyphrases = extractor.get_n_best(n=top_n)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases\n",
        "\n",
        "def extract_kp_miner_keywords(text, top_n=10, language='en', normalization=None, \n",
        "                              lasf=2, cutoff=200, alpha=2.3, sigma=3.0, \n",
        "                              only_keywords=True):\n",
        "    extractor = pke.unsupervised.KPMiner()\n",
        "    extractor.load_document(input=text, language=language, normalization=normalization)\n",
        "    extractor.candidate_selection(lasf=lasf, cutoff=cutoff)\n",
        "    extractor.candidate_weighting(alpha=alpha, sigma=sigma)\n",
        "    keyphrases = extractor.get_n_best(top_n)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases\n",
        "\n",
        "def extract_yake_keywords(text, top_n=10, normalization=None, window=2, \n",
        "                          threshold=0.8, language='en', n=3, use_stems=False, \n",
        "                          only_keywords=True):\n",
        "    stoplist = stopwords.words('english')\n",
        "    extractor = pke.unsupervised.YAKE()\n",
        "    extractor.load_document(input=text, language=language, normalization=normalization)\n",
        "    extractor.candidate_selection(n=n, stoplist=stoplist)\n",
        "    extractor.candidate_weighting(window=window, stoplist=stoplist, use_stems=use_stems)\n",
        "    keyphrases = extractor.get_n_best(n=top_n, threshold=threshold)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases\n",
        "\n",
        "\n",
        "## Graph based algorithms\n",
        "def extract_textrank_keywords(text, top_n=10, language='en', normalization=None, \n",
        "                              window=2, top_percent=0.33, only_keywords=True):\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "    extractor = pke.unsupervised.TextRank()\n",
        "    extractor.load_document(input=text, language=language, normalization=normalization)\n",
        "    extractor.candidate_weighting(window=window, pos=pos, top_percent=top_percent)\n",
        "    keyphrases = extractor.get_n_best(n=top_n)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases\n",
        "\n",
        "def extract_singlerank_keywords(text, top_n=10, language='en', normalization=None,\n",
        "                                window=10,only_keywords=True):\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "    extractor = pke.unsupervised.SingleRank()\n",
        "    extractor.load_document(input=text, language=language, normalization=normalization)\n",
        "    extractor.candidate_selection(pos=pos)\n",
        "    extractor.candidate_weighting(window=window, pos=pos)\n",
        "    keyphrases = extractor.get_n_best(n=top_n)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases\n",
        "\n",
        "def extract_topicrank_keywords(text, top_n=10, language='en', only_keywords=True):\n",
        "    extractor = pke.unsupervised.TopicRank()\n",
        "    extractor.load_document(input=text, language=language)\n",
        "    extractor.candidate_selection()\n",
        "    extractor.candidate_weighting()\n",
        "    keyphrases = extractor.get_n_best(n=top_n)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases\n",
        "\n",
        "def extract_multipartiterank_keywords(text, top_n=10, language='en', alpha=1.1, \n",
        "                                      threshold=0.74, method='average', \n",
        "                                      only_keywords=True):\n",
        "    stoplist = list(string.punctuation)\n",
        "    stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "    stoplist += stopwords.words('english')\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    extractor.load_document(input=text, language=language)\n",
        "    extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "    extractor.candidate_weighting(alpha=alpha, threshold=threshold, method=method)\n",
        "    keyphrases = extractor.get_n_best(n=top_n)\n",
        "    if only_keywords:\n",
        "        keyphrases = [phrase for phrase, score in keyphrases]\n",
        "    return keyphrases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J33F3vxV7EPM"
      },
      "source": [
        "The next cell:\n",
        "\n",
        "* **collects the above functions** for keyword extraction together with a set of keyword arguments for easy access in a dictionary,\n",
        "* sets a **default subset of extraction functions** to compare, and \n",
        "* defines a **convenience function** that simplifies the **comparison** of the different extraction methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6chHxkQU46Y"
      },
      "source": [
        "# Define extraction functions, labels, and set parameters\n",
        "top_n = 10\n",
        "\n",
        "KEYWORD_EXTRACTION_FUNCTIONS = {\n",
        "    # Statistical models\n",
        "    'TFIDF': (\n",
        "        extract_tfidf_keywords, \n",
        "        {'top_n': top_n},\n",
        "    ),\n",
        "    'KPMiner': (\n",
        "        extract_kp_miner_keywords, \n",
        "        {'top_n': top_n},\n",
        "    ),\n",
        "    'YAKE': (\n",
        "        extract_yake_keywords, \n",
        "        {'top_n': top_n},\n",
        "    ),\n",
        "    # Graph-based models\n",
        "    'TextRank': (\n",
        "        extract_textrank_keywords, \n",
        "        {'top_n': top_n ,'window': 2},\n",
        "    ),\n",
        "    'SingleRank': (\n",
        "        extract_singlerank_keywords, \n",
        "        {'top_n': top_n, 'window': 10},\n",
        "    ),\n",
        "    'TopicRank': (\n",
        "        extract_topicrank_keywords, \n",
        "        {'top_n': top_n},\n",
        "    ),\n",
        "    'MultipartiteRank': (\n",
        "        extract_multipartiterank_keywords, \n",
        "        {'top_n': top_n},\n",
        "    ),\n",
        "    # Supervised\n",
        "    'KEA': (\n",
        "        extract_kea_keywords, \n",
        "        {'top_n': top_n},\n",
        "    ),\n",
        "}\n",
        "\n",
        "DEFAULT_SELECTION = ['TFIDF', 'YAKE', 'TextRank', 'TopicRank', 'KEA']\n",
        "\n",
        "def compare_keyword_extraction_algorithms(text, \n",
        "                                          keyword_extraction_functions=None,\n",
        "                                          selection=None):\n",
        "    \"\"\"Convenience function compare extracted keywords from the given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to extract keywords from.\n",
        "        keyword_extraction_functions (dict): Dict containing labels as keys and\n",
        "            a tuple of (extraction_function, kwargs) as values. Defaults to None.\n",
        "        selection (list): List of names of algorithm to use for keyword \n",
        "            extraction. See keyword_extraction_functions for possible values\n",
        "            and/or to change arguments. Defaults to None.\n",
        "    \"\"\"\n",
        "    if keyword_extraction_functions is None:\n",
        "        keyword_extraction_functions = KEYWORD_EXTRACTION_FUNCTIONS\n",
        "    if selection is None:\n",
        "        selection = DEFAULT_SELECTION\n",
        "    \n",
        "    # Create DataFrame with extracted keywords\n",
        "    all_keywords = pd.DataFrame(\n",
        "        zip_longest(\n",
        "            *(extraction_fn(text, **kwargs)\n",
        "                for name, (extraction_fn, kwargs) in keyword_extraction_functions.items()\n",
        "                if name in selection\n",
        "            ),\n",
        "            fillvalue=\"\",\n",
        "        ),\n",
        "        columns=selection,\n",
        "    )\n",
        "    \n",
        "    # Display table\n",
        "    display(all_keywords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTd5gkJ2Hi2g"
      },
      "source": [
        "With the keyword extractions functions implemented let's define a **few short example texts** which will be used below for keyword extraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6OAlOYJhpAm"
      },
      "source": [
        "texts = [\n",
        "    # Dartmouth Workshop\n",
        "    # https://en.wikipedia.org/wiki/Dartmouth_workshop\n",
        "    (\n",
        "        \"The Dartmouth Summer Research Project on Artificial Intelligence was \"\n",
        "        \"a 1956 summer workshop widely considered to be the founding event of \"\n",
        "        \"artificial intelligence as a field. The project lasted approximately \"\n",
        "        \"six to eight weeks and was essentially an extended brainstorming \"\n",
        "        \"session. Eleven mathematicians and scientists originally planned to \"\n",
        "        \"attend; not all of them attended, but more than ten others came for \"\n",
        "        \"short times.\"\n",
        "    ),\n",
        "    # Abstract TextRank Paper\n",
        "    (\n",
        "        \"In this paper, we introduce TextRank ‚Äì a graph-based ranking model \" \n",
        "        \"for text processing, and show how this model can be successfully \"\n",
        "        \"used in natural language applications. In particular, we propose \"\n",
        "        \"two innovative unsupervised methods for keyword and sentence \"\n",
        "        \"extraction, and show that the results obtained compare favorably \"\n",
        "        \"with previously published results on established benchmarks.\"\n",
        "     ),\n",
        "    # News\n",
        "    # https://www.nytimes.com/live/2021/02/09/us/trump-impeachment-trial\n",
        "    (\n",
        "        \"The House managers prosecuting former President Donald J. Trump \"\n",
        "        \"opened his Senate impeachment trial on Tuesday with a vivid and \"\n",
        "        \"graphic sequence of footage of his supporters storming the Capitol \"\n",
        "        \"last month in an effort to prevent Congress from finalizing his \"\n",
        "        \"election defeat.\\n\"\n",
        "        \"The managers wasted no time moving immediately to their most powerful \"\n",
        "        \"evidence: the explicit visual record of the deadly Capitol siege \"\n",
        "        \"that threatened the lives of former Vice President Mike Pence and \"\n",
        "        \"members of both houses of Congress juxtaposed against Mr. Trump‚Äôs \"\n",
        "        \"own words encouraging members of the mob at a rally beforehand.\\n\"\n",
        "        \"The scenes of mayhem and violence ‚Äî punctuated by expletives rarely \"\n",
        "        \"heard on the floor of the Senate ‚Äî highlighted the drama of the \"\n",
        "        \"trial in gut-punching fashion for the senators who lived through \"\n",
        "        \"the events barely a month ago and now sit as quasi-jurors. On the \"\n",
        "        \"screens, they saw enraged extremists storming barricades, beating \"\n",
        "        \"police officers, setting up a gallows and yelling, ‚ÄúTake the \"\n",
        "        \"building,‚Äù ‚ÄúFight for Trump‚Äù and ‚ÄúPence is a traitor! Traitor Pence!‚Äù\"\n",
        "    ),\n",
        "    # Recipe\n",
        "    # https://www.nytimes.com/2021/02/08/dining/birria-recipes.html\n",
        "    (\n",
        "        \"You go to Birrieria Nochistl√°n for the Moreno family‚Äôs \"\n",
        "        \"Zacatecan-style birria ‚Äî a big bowl of hot goat meat submerged \"\n",
        "        \"in a dark pool of its own concentrated cooking juices.\\n\"\n",
        "        \"Right out of the pot, the steamed meat isn‚Äôt just tender, but \"\n",
        "        \"in places deliciously sticky, smudged with chile adobo, falling \"\n",
        "        \"apart, barely even connected to the bone. It comes with thick, \"\n",
        "        \"soft tortillas, made to order, and a vibrant salsa roja. \"\n",
        "        \"The Moreno family has been serving birria exactly like this for \"\n",
        "        \"about 20 years.\\n\"\n",
        "        \"‚ÄúSometimes I think we should update our menu,‚Äù said Rosio Moreno, \"\n",
        "        \"23, whose parents started the business out of their home in East \"\n",
        "        \"Los Angeles. ‚ÄúBut we don‚Äôt want to change the way we do things \"\n",
        "        \"because of the hype.‚Äù\"\n",
        "    ),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-LxGJKZYPBo"
      },
      "source": [
        "# Compare the keywords extracted by the given algorithms\n",
        "selected_algorithms = ['TFIDF', 'KPMiner', 'YAKE', 'TextRank', 'TopicRank', 'KEA']\n",
        "\n",
        "for text in texts:\n",
        "    compare_keyword_extraction_algorithms(text, selection=selected_algorithms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MgPSWDPK63I"
      },
      "source": [
        "## üßë‚Äçüî¨ Try it yourself!\n",
        "\n",
        "**Task**: \n",
        "\n",
        "1. Insert your own text that you would like to extract keywords from\n",
        "2. Select the desired keyword extraction methods\n",
        "3. Extract keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I-doP6EKYf8"
      },
      "source": [
        "# Task 1: Add your own input text from which you want to extract keywords\n",
        "text = \"Replace this string rambling on about keyword extraction and how great it is with your own text\"\n",
        "\n",
        "# Task 2: Select the desired keyword extraction methods you want to compare\n",
        "selected_algorithms = ['TFIDF', 'YAKE', 'TextRank', 'TopicRank', 'KEA']\n",
        "\n",
        "# Task 3: Execute this cell to compare the extracted keywords\n",
        "compare_keyword_extraction_algorithms(text, selection=selected_algorithms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24OdEWW7Jz24"
      },
      "source": [
        "## Summary\n",
        "\n",
        "When starting a new project that can benefit from keyword extraction **we recommend** to try **`pke`** first. It is easy to use, offers a good selection of keyword extraction methods (*batteries included*), and if nothing else provides strong baselines for more advanced methods. \n",
        "\n",
        "TextRank is a good starting point which only requires part-of-speech tagging. If this information is unavailable, YAKE is an interesting alternative with the fewest dependencies.\n",
        "Lastly, even though all models come pre-trained TF‚ÄìIDF and supervised models can yield much improved results if a training corpus or large collection of similar documents is at hand.\n",
        "\n",
        "As this notebook shows, the hole on the NLP practitioner's tool belt left by the removal of Gensim's keyword extraction functionality will easily be filled by an entire toolkit: `pke`.\n",
        "\n",
        "The times of only having a hammer to solve keyword extraction are over, such that non-English languages don't need to look like nails any longer!\n",
        "\n",
        "\n",
        "## Resources\n",
        "\n",
        "### üìö Libraries & Packages\n",
        "\n",
        "* [`pke` python keyphrase extraction](https://github.com/boudinfl/pke): Neat library implementing amongst others TF-IDF, YAKE, KPMiner, TextRank, SingleRank, TopicRank, TopologicalPageRank, PositionRank, MultipartiteRank, KEA, and WINGNUS. Uses GPLv3 licence.[[documentation](https://boudinfl.github.io/pke/)]\n",
        "* [YAKE](https://github.com/LIAAD/yake): An alternative implementation from the authors of the YAKE paper.\n",
        "* [PyTextRank](https://github.com/DerwenAI/pytextrank): An alternative Python implementation of *TextRank* as a *spaCy pipeline extension*.\n",
        "* [Gensim 3.8](https://radimrehurek.com/gensim_3.8.3/summarization/keywords.html): Most widely used package for keyword extraction. The upcoming **version 4.0 [removes summarization](https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4#12-removed-gensimsummarization)** module (which includes keyword extraction), because of bad performance. (Is this a good or a bad thing? üôÉ)\n",
        "\n",
        "\n",
        "### üìÑ Overview Papers\n",
        "\n",
        "* *Keyword extraction: a review of methods and approaches* by Slobodan Beliga (2014)\n",
        " [[paper](http://langnet.uniri.hr/papers/beliga/Beliga_KeywordExtraction_a_review_of_methods_and_approaches.pdf)]\n",
        "* *A Review of Keyphrase Extraction* by Eirini Papagiannopoulou and Grigorios Tsoumakas (2019) [[paper](https://arxiv.org/pdf/1905.05044)]"
      ]
    }
  ]
}