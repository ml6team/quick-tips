{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of smllr_mdls.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GRL0jz-Rx6pY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hp3Msndwc3y"
      },
      "source": [
        "## Compact Transformers  ü§è\n",
        "\n",
        "We all know bigger is often better! Nothing cooler than rolling up in your larger-than-life Transformer model. Who doesn't want to drive a monster truck once in their life...\n",
        "\n",
        "However, monster trucks aren't always practical in real life. Models need to run smoothly in production. So the best model size is often the one most suited for your practical situation and requirements.\n",
        "\n",
        "In this tip, we'll have a look at some sub-25million parameter transformer models available in Huggingface. So you can have both a smoothly running application and brag to your manager that you implemented transformers!\n",
        "\n",
        "### The test üî®\n",
        "We will be evaluating all of our candidates on a few fronts:\n",
        "\n",
        "\n",
        "*   GPU memory during finetune: relevant in case of hardware or cost limits\n",
        "*   GPU memory during inference: relevant when running on edge device\n",
        "*   Model artefact size: relevant when facing hardware restrictions\n",
        "*   Model CPU & GPU inference time: relevant when dealing with latency restrictions\n",
        "*   Time taken to finetune: relevant when dealing with frequent retraining loops\n",
        "\n",
        "All of these benchmarked against the final performance after training for one epoch!\n",
        "\n",
        "*Note: tests were done in Google Colab, with a V100 GPU.*\n",
        "\n",
        "... let the games begin üèãÔ∏è‚Äç‚ôÄÔ∏è\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rcrjcbtxqgB"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wOyTvejwaZn"
      },
      "source": [
        "!pip install -q transformers sentencepiece datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Check GPU:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRL0jz-Rx6pY"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAR1BIJ3xyaz"
      },
      "source": [
        "from transformers import AutoTokenizer\r\n",
        "from datasets import load_dataset\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\r\n",
        "\r\n",
        "from transformers import AutoModelForSequenceClassification\r\n",
        "from transformers import Trainer, TrainingArguments\r\n",
        "\r\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olu-YuKHx-Qs"
      },
      "source": [
        "### Data\r\n",
        "\r\n",
        "For this tip, we will look at a simple and straightforward NLP task of classifying some news headlines in various categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWfkfAPAx-4v"
      },
      "source": [
        "dataset = load_dataset(\"ag_news\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxVXznYIz7hr"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBEoFgUM5Aov"
      },
      "source": [
        "!mkdir tests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZG6e2ZmFmZi"
      },
      "source": [
        "def compute_metrics(p):\r\n",
        "    preds = np.argmax(p.predictions, axis=1)\r\n",
        "    return {\r\n",
        "        \"accuracy\": (preds == p.label_ids).mean()\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuNrt_aQes10"
      },
      "source": [
        "in the below segment, feel free to tweak the `max_steps` parameter for faster notebook execution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NYVfaCAFPda"
      },
      "source": [
        "def train_and_evaluate_model(model_name):\r\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\r\n",
        "\r\n",
        "    def tokenize(batch):\r\n",
        "        return tokenizer(batch['text'], padding=True, truncation=True)\r\n",
        "\r\n",
        "    train_dataset, test_dataset = load_dataset('ag_news', split=['train', 'test'])\r\n",
        "    train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\r\n",
        "    test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\r\n",
        "    train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\r\n",
        "    test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\r\n",
        "\r\n",
        "    training_args = TrainingArguments(\r\n",
        "        output_dir='./results',          # output directory\r\n",
        "        num_train_epochs=1,             # total number of training epochs\r\n",
        "        per_device_train_batch_size=16,  # batch size per device during training\r\n",
        "        per_device_eval_batch_size=64,   # batch size for evaluation\r\n",
        "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\r\n",
        "        weight_decay=0.01,               # strength of weight decay\r\n",
        "        #logging_dir='./logs',            # directory for storing logs\r\n",
        "        learning_rate=2e-5,\r\n",
        "        evaluation_strategy='epoch',\r\n",
        "        max_steps=2500\r\n",
        "    )\r\n",
        "\r\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\r\n",
        "        model_name, \r\n",
        "        num_labels=4\r\n",
        "    )\r\n",
        "\r\n",
        "    # Get the number of parameters\r\n",
        "\r\n",
        "    parameters = model.num_parameters()\r\n",
        "\r\n",
        "    # Finetune the model\r\n",
        "\r\n",
        "    trainer = Trainer(\r\n",
        "        model=model,\r\n",
        "        args=training_args,\r\n",
        "        compute_metrics=compute_metrics,\r\n",
        "        train_dataset=train_dataset,\r\n",
        "        eval_dataset=test_dataset,\r\n",
        "    )\r\n",
        "\r\n",
        "    start_time = time.time()\r\n",
        "\r\n",
        "    trainer.train()\r\n",
        "\r\n",
        "    duration = time.time() - start_time\r\n",
        "\r\n",
        "    # Get the metrics\r\n",
        "\r\n",
        "    metrics = trainer.evaluate()\r\n",
        "\r\n",
        "    # Store the model\r\n",
        "    trainer.save_model(f\"tests/{model_name}\")\r\n",
        "    tokenizer.save_pretrained(f\"tests/{model_name}\")\r\n",
        "\r\n",
        "    return parameters, metrics, duration\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGdgY-7Dc6JY"
      },
      "source": [
        "run_dict = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJFEeT8YEGgV"
      },
      "source": [
        "Now meet our contenders:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tQHGGpC0EXr"
      },
      "source": [
        "#### MobileBert\n",
        "\n",
        "A knowledge-transfer model based on a BERT_LARGE-derivated teacher, with some architectural tricks. Claims a 62ms latency on a Pixel 4 phone!\n",
        "\n",
        "[link to paper](https://arxiv.org/abs/2004.02984)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3euzbUaFwax"
      },
      "source": [
        "model_name = 'google/mobilebert-uncased'\r\n",
        "parameters, metrics, duration = train_and_evaluate_model(model_name)\r\n",
        "run_dict.append({\r\n",
        "    \"name\": \"mobilebert\",\r\n",
        "    \"model_name\": model_name,\r\n",
        "    \"parameters\": parameters,\r\n",
        "    \"gpu_memory_finetune\": 9035,\r\n",
        "    \"gpu_memory_inference\": 1481,\r\n",
        "    \"artefact_size\": 147,\r\n",
        "    \"duration\": duration,\r\n",
        "    \"metrics\": metrics\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8teW9_JFMvM"
      },
      "source": [
        "#### ALBert\r\n",
        "Through two clever parameter-reduction techniques, the memory footprint of this model could be reduced in comparison with BERT.\r\n",
        "\r\n",
        "[link to paper](https://arxiv.org/pdf/1909.11942.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJE0ImZMEuLc"
      },
      "source": [
        "model_name = 'albert-base-v2'\r\n",
        "parameters, metrics, duration = train_and_evaluate_model(model_name)\r\n",
        "run_dict.append({\r\n",
        "    \"name\": \"albert\",\r\n",
        "    \"model_name\": model_name,\r\n",
        "    \"parameters\": parameters,\r\n",
        "    \"gpu_memory_finetune\": 12023,\r\n",
        "    \"gpu_memory_inference\": 1397,\r\n",
        "    \"artefact_size\": 47.4,\r\n",
        "    \"duration\": duration,\r\n",
        "    \"metrics\": metrics\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-lGQBySN0SX"
      },
      "source": [
        "#### TinyBert\r\n",
        "Result of a novel Knowledge Distillation (KD) method, accompanied by a two-stage learning framework.\r\n",
        "\r\n",
        "[link to paper](https://arxiv.org/abs/1909.10351)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdPdpcp_GEjH"
      },
      "source": [
        "model_name = 'huawei-noah/TinyBERT_General_4L_312D'\r\n",
        "parameters, metrics, duration = train_and_evaluate_model(model_name)\r\n",
        "run_dict.append({\r\n",
        "    \"name\": \"tinybert\",\r\n",
        "    \"model_name\": model_name,\r\n",
        "    \"parameters\": parameters,\r\n",
        "    \"gpu_memory_finetune\": 3797,\r\n",
        "    \"gpu_memory_inference\": 1405,\r\n",
        "    \"artefact_size\": 62.7,\r\n",
        "    \"duration\": duration,\r\n",
        "    \"metrics\": metrics\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amb7WiAgyBdH"
      },
      "source": [
        "#### BERT-small\r\n",
        "The following three are all results of so-called Pre-trained Distillation, allowing more compact models to yield better performance.\r\n",
        "\r\n",
        "[link to paper](https://arxiv.org/abs/1908.08962)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1X7KQhsyBUX"
      },
      "source": [
        "model_name = 'google/bert_uncased_L-4_H-512_A-8'\r\n",
        "parameters, metrics, duration = train_and_evaluate_model(model_name)\r\n",
        "run_dict.append({\r\n",
        "    \"name\": \"bert-small\",\r\n",
        "    \"model_name\": model_name,\r\n",
        "    \"parameters\": parameters,\r\n",
        "    \"gpu_memory_finetune\": 3797,\r\n",
        "    \"gpu_memory_inference\": 1459,\r\n",
        "    \"artefact_size\": 116,\r\n",
        "    \"duration\": duration,\r\n",
        "    \"metrics\": metrics\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D8SJ_gKxMNL"
      },
      "source": [
        "#### BERT-mini\r\n",
        "\r\n",
        "[link to paper](https://arxiv.org/abs/1908.08962)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F52Y3L8KxMgj"
      },
      "source": [
        "model_name = 'google/bert_uncased_L-4_H-256_A-4'\r\n",
        "parameters, metrics, duration = train_and_evaluate_model(model_name)\r\n",
        "run_dict.append({\r\n",
        "    \"name\": \"bert-mini\",\r\n",
        "    \"model_name\": model_name,\r\n",
        "    \"parameters\": parameters,\r\n",
        "    \"gpu_memory_finetune\": 2579,\r\n",
        "    \"gpu_memory_inference\": 1383,\r\n",
        "    \"artefact_size\": 45.1,\r\n",
        "    \"duration\": duration,\r\n",
        "    \"metrics\": metrics\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0GSbIe9PVOX"
      },
      "source": [
        "#### BERT-tiny\r\n",
        "\r\n",
        "[link to paper](https://arxiv.org/abs/1908.08962)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqk4XDYOS6C"
      },
      "source": [
        "model_name = 'google/bert_uncased_L-2_H-128_A-2'\r\n",
        "parameters, metrics, duration = train_and_evaluate_model(model_name)\r\n",
        "run_dict.append({\r\n",
        "    \"name\": \"bert-tiny\",\r\n",
        "    \"model_name\": model_name,\r\n",
        "    \"parameters\": parameters,\r\n",
        "    \"gpu_memory_finetune\": 1695,\r\n",
        "    \"gpu_memory_inference\": 1357,\r\n",
        "    \"artefact_size\": 17.8,\r\n",
        "    \"duration\": duration,\r\n",
        "    \"metrics\": metrics\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZLGi__aitIl"
      },
      "source": [
        "#### Distilbert\r\n",
        "\r\n",
        "A true classic default for our finetuning efforts! Serves as a bit of a baseline against which we will compare the smaller models.\r\n",
        "\r\n",
        "[link to paper](https://arxiv.org/abs/1910.01108)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgDxs-RniR8-"
      },
      "source": [
        "model_name = 'distilbert-base-uncased'\r\n",
        "parameters, metrics, duration = train_and_evaluate_model(model_name)\r\n",
        "run_dict.append({\r\n",
        "    \"name\": \"distilbert\",\r\n",
        "    \"model_name\": model_name,\r\n",
        "    \"parameters\": parameters,\r\n",
        "    \"gpu_memory_finetune\": 6691,\r\n",
        "    \"gpu_memory_inference\": 1631,\r\n",
        "    \"artefact_size\": 268,\r\n",
        "    \"duration\": duration,\r\n",
        "    \"metrics\": metrics\r\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7dCgYOJrZNC"
      },
      "source": [
        "### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d89uh1aL7lf1"
      },
      "source": [
        "from transformers import TextClassificationPipeline, pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU2M8Icd8Q9o"
      },
      "source": [
        "test_sentence = \"Today, Google, Facebook and Amazon announced that they would be joining hands in releasing a new unified AI framework called TensorBro.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSTCh8eJe8pi"
      },
      "source": [
        "#### Batches prediction speed on GPU\n",
        "Model size impacts the max batch-size, and thus affects how many sentences we can process per second. For each model, we try to find out the max batch-size (per increment of 5000), and how long it takes for to predict this batch. This could near the theoretical prediction speed when deploying this model on a similar GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW2M-ijHXuji"
      },
      "source": [
        "final_count = 0\r\n",
        "final_time = 0\r\n",
        "\r\n",
        "for model in run_dict:\r\n",
        "    print(f\"testing model {model.get('model_name')}\")\r\n",
        "    test_pipe = pipeline(\"sentiment-analysis\",f\"tests/{model.get('model_name')}\", device=0)\r\n",
        "    try:\r\n",
        "        for i in range(1, 100000, 5000):\r\n",
        "            print(f\"Trying size {i}\")\r\n",
        "            start_time = time.time()\r\n",
        "            result=test_pipe([test_sentence]*i)\r\n",
        "            final_time = time.time() - start_time\r\n",
        "            final_count = i\r\n",
        "            time.sleep(10)\r\n",
        "    except RuntimeError as e:\r\n",
        "        print(e)\r\n",
        "        model[\"inference_time_max_batch\"] = final_time\r\n",
        "        model[\"inference_size_max_batch\"] = final_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOlY_fh266s3"
      },
      "source": [
        "#### Sequential CPU inference time\r\n",
        "GPU's are costly, so sometimes you wanna do sequential performance or performance on a CPU. Let's test this out as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Pu02HM7AI3"
      },
      "source": [
        "for model in run_dict:\r\n",
        "    test_pipe = pipeline(\"sentiment-analysis\",f\"tests/{model.get('model_name')}\", device=-1)\r\n",
        "\r\n",
        "    start_time = time.time()\r\n",
        "    for i in range(100):\r\n",
        "        test_pipe(test_sentence)\r\n",
        "    \r\n",
        "    duration = time.time() - start_time\r\n",
        "\r\n",
        "    # Average out\r\n",
        "    duration /= 100.\r\n",
        "\r\n",
        "    # Express in msec\r\n",
        "    duration *= 1000.\r\n",
        "\r\n",
        "\r\n",
        "    model[\"inference_time_cpu\"] = duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOPGjx-f7A6t"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W35fk-nxsDYX"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozq4juZLr13v"
      },
      "source": [
        "df_data = pd.DataFrame(run_dict)\r\n",
        "df_data['eval_accuracy'] = df_data.metrics.apply(lambda x: x['eval_accuracy'])\r\n",
        "df_data['batched_prediction_speed'] = df_data.inference_size_max_batch / df_data.inference_time_max_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "WhT-EvzvBxlk",
        "outputId": "56a5ad1b-2848-4ac3-cb83-f22bbfe2bede"
      },
      "source": [
        "df_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>model_name</th>\n",
              "      <th>parameters</th>\n",
              "      <th>gpu_memory_finetune</th>\n",
              "      <th>gpu_memory_inference</th>\n",
              "      <th>artefact_size</th>\n",
              "      <th>duration</th>\n",
              "      <th>metrics</th>\n",
              "      <th>inference_time_max_batch</th>\n",
              "      <th>inference_size_max_batch</th>\n",
              "      <th>inference_time_cpu</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <th>batched_prediction_speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mobilebert</td>\n",
              "      <td>google/mobilebert-uncased</td>\n",
              "      <td>24583940</td>\n",
              "      <td>9035</td>\n",
              "      <td>1481</td>\n",
              "      <td>147.0</td>\n",
              "      <td>1701.219089</td>\n",
              "      <td>{'eval_loss': 0.2605212330818176, 'eval_accura...</td>\n",
              "      <td>15.224273</td>\n",
              "      <td>20001</td>\n",
              "      <td>52.183349</td>\n",
              "      <td>0.918684</td>\n",
              "      <td>1313.757337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>albert</td>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>11686660</td>\n",
              "      <td>12023</td>\n",
              "      <td>1397</td>\n",
              "      <td>47.4</td>\n",
              "      <td>3460.138656</td>\n",
              "      <td>{'eval_loss': 0.23464326560497284, 'eval_accur...</td>\n",
              "      <td>12.188317</td>\n",
              "      <td>5001</td>\n",
              "      <td>113.805959</td>\n",
              "      <td>0.925132</td>\n",
              "      <td>410.310946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tinybert</td>\n",
              "      <td>huawei-noah/TinyBERT_General_4L_312D</td>\n",
              "      <td>14351500</td>\n",
              "      <td>3797</td>\n",
              "      <td>1405</td>\n",
              "      <td>62.7</td>\n",
              "      <td>408.087370</td>\n",
              "      <td>{'eval_loss': 0.3276883363723755, 'eval_accura...</td>\n",
              "      <td>5.773093</td>\n",
              "      <td>25001</td>\n",
              "      <td>9.504721</td>\n",
              "      <td>0.894079</td>\n",
              "      <td>4330.607180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bert-small</td>\n",
              "      <td>google/bert_uncased_L-4_H-512_A-8</td>\n",
              "      <td>28765700</td>\n",
              "      <td>3797</td>\n",
              "      <td>1459</td>\n",
              "      <td>116.0</td>\n",
              "      <td>549.804414</td>\n",
              "      <td>{'eval_loss': 0.2530038058757782, 'eval_accura...</td>\n",
              "      <td>5.292146</td>\n",
              "      <td>15001</td>\n",
              "      <td>19.072402</td>\n",
              "      <td>0.914079</td>\n",
              "      <td>2834.578027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bert-mini</td>\n",
              "      <td>google/bert_uncased_L-4_H-256_A-4</td>\n",
              "      <td>11171588</td>\n",
              "      <td>2579</td>\n",
              "      <td>1383</td>\n",
              "      <td>45.1</td>\n",
              "      <td>252.107582</td>\n",
              "      <td>{'eval_loss': 0.3101600706577301, 'eval_accura...</td>\n",
              "      <td>5.392508</td>\n",
              "      <td>30001</td>\n",
              "      <td>6.873202</td>\n",
              "      <td>0.902105</td>\n",
              "      <td>5563.459987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bert-tiny</td>\n",
              "      <td>google/bert_uncased_L-2_H-128_A-2</td>\n",
              "      <td>4386436</td>\n",
              "      <td>1695</td>\n",
              "      <td>1357</td>\n",
              "      <td>17.8</td>\n",
              "      <td>121.611590</td>\n",
              "      <td>{'eval_loss': 0.4182027280330658, 'eval_accura...</td>\n",
              "      <td>7.484345</td>\n",
              "      <td>70001</td>\n",
              "      <td>2.526121</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>9352.989822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>distilbert</td>\n",
              "      <td>distilbert-base-uncased</td>\n",
              "      <td>66956548</td>\n",
              "      <td>6691</td>\n",
              "      <td>1631</td>\n",
              "      <td>268.0</td>\n",
              "      <td>1509.763152</td>\n",
              "      <td>{'eval_loss': 0.21709568798542023, 'eval_accur...</td>\n",
              "      <td>11.219041</td>\n",
              "      <td>10001</td>\n",
              "      <td>59.247344</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>891.430889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         name  ... batched_prediction_speed\n",
              "0  mobilebert  ...              1313.757337\n",
              "1      albert  ...               410.310946\n",
              "2    tinybert  ...              4330.607180\n",
              "3  bert-small  ...              2834.578027\n",
              "4   bert-mini  ...              5563.459987\n",
              "5   bert-tiny  ...              9352.989822\n",
              "6  distilbert  ...               891.430889\n",
              "\n",
              "[7 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "AC-8prB_vKwD",
        "outputId": "e696b66e-8357-474a-b916-69268f616669"
      },
      "source": [
        "import plotly.express as px\r\n",
        "\r\n",
        "fig = px.scatter(\r\n",
        "    df_data,\r\n",
        "    title=\"Accuracy vs finetune time and required GPU memory\",\r\n",
        "    labels={\r\n",
        "        \"duration\": \"Time (sec) to finetune for 1 epoch\",\r\n",
        "        \"eval_accuracy\": \"Accuracy on the test-set\"\r\n",
        "    },\r\n",
        "    x=\"duration\",\r\n",
        "    y=\"eval_accuracy\",\r\n",
        "    size=\"gpu_memory_finetune\", hover_name=\"name\", size_max=100)\r\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"7c83b46d-848b-484e-9c62-3237987aba0a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"7c83b46d-848b-484e-9c62-3237987aba0a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '7c83b46d-848b-484e-9c62-3237987aba0a',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"<b>%{hovertext}</b><br><br>Time (sec) to finetune for 1 epoch=%{x}<br>Accuracy on the test-set=%{y}<br>gpu_memory_finetune=%{marker.size}\", \"hovertext\": [\"mobilebert\", \"albert\", \"tinybert\", \"bert-small\", \"bert-mini\", \"bert-tiny\", \"distilbert\"], \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"size\": [9035, 12023, 3797, 3797, 2579, 1695, 6691], \"sizemode\": \"area\", \"sizeref\": 1.2023, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1701.2190890312195, 3460.1386563777924, 408.08736991882324, 549.8044140338898, 252.10758233070374, 121.61159038543701, 1509.7631516456604], \"xaxis\": \"x\", \"y\": [0.9186842105263158, 0.9251315789473684, 0.8940789473684211, 0.9140789473684211, 0.9021052631578947, 0.88, 0.9275], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"itemsizing\": \"constant\", \"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy vs finetune time and required GPU memory\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Time (sec) to finetune for 1 epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Accuracy on the test-set\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7c83b46d-848b-484e-9c62-3237987aba0a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "GXfyHs7KvSaz",
        "outputId": "f02bfaac-00b3-4145-f476-a7029103b7fa"
      },
      "source": [
        "fig = px.scatter(\r\n",
        "    df_data,\r\n",
        "    title=\"Accuracy vs CPU inference time and model artefact size (Mb)\",\r\n",
        "    labels={\r\n",
        "        \"inference_time_cpu\": \"Inference time (ms) on CPU\",\r\n",
        "        \"eval_accuracy\": \"Accuracy on the test-set\"\r\n",
        "    },\r\n",
        "    x=\"inference_time_cpu\",\r\n",
        "    y=\"eval_accuracy\",\r\n",
        "    size=\"artefact_size\", hover_name=\"name\", size_max=100)\r\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"a43b49a7-3ada-485c-b5ff-4c8478fec520\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"a43b49a7-3ada-485c-b5ff-4c8478fec520\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'a43b49a7-3ada-485c-b5ff-4c8478fec520',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"<b>%{hovertext}</b><br><br>Inference time (ms) on CPU=%{x}<br>Accuracy on the test-set=%{y}<br>artefact_size=%{marker.size}\", \"hovertext\": [\"mobilebert\", \"albert\", \"tinybert\", \"bert-small\", \"bert-mini\", \"bert-tiny\", \"distilbert\"], \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"size\": [147.0, 47.4, 62.7, 116.0, 45.1, 17.8, 268.0], \"sizemode\": \"area\", \"sizeref\": 0.0268, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [52.18334913253784, 113.80595922470093, 9.50472116470337, 19.072401523590088, 6.873202323913574, 2.526121139526367, 59.24734354019165], \"xaxis\": \"x\", \"y\": [0.9186842105263158, 0.9251315789473684, 0.8940789473684211, 0.9140789473684211, 0.9021052631578947, 0.88, 0.9275], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"itemsizing\": \"constant\", \"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy vs CPU inference time and model artefact size (Mb)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Inference time (ms) on CPU\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Accuracy on the test-set\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a43b49a7-3ada-485c-b5ff-4c8478fec520');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "DW4Omz_CwMWW",
        "outputId": "0820ee41-1f1e-4f3f-c62e-8d630e11df49"
      },
      "source": [
        "fig = px.scatter(\r\n",
        "    df_data,\r\n",
        "    title=\"Accuracy vs GPU batches prediction speed and model artefact size (Mb)\",\r\n",
        "    labels={\r\n",
        "        \"batched_prediction_speed\": \"Prediction speed (sentences/sec) at max batch size\",\r\n",
        "        \"eval_accuracy\": \"Accuracy on the test-set\"\r\n",
        "    },\r\n",
        "    x=\"batched_prediction_speed\",\r\n",
        "    y=\"eval_accuracy\",\r\n",
        "    size=\"artefact_size\", hover_name=\"name\", size_max=100)\r\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d27dcf83-4d8c-4329-b754-c41470565897\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d27dcf83-4d8c-4329-b754-c41470565897\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd27dcf83-4d8c-4329-b754-c41470565897',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"<b>%{hovertext}</b><br><br>Prediction speed (sentences/sec) at max batch size=%{x}<br>Accuracy on the test-set=%{y}<br>artefact_size=%{marker.size}\", \"hovertext\": [\"mobilebert\", \"albert\", \"tinybert\", \"bert-small\", \"bert-mini\", \"bert-tiny\", \"distilbert\"], \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"size\": [147.0, 47.4, 62.7, 116.0, 45.1, 17.8, 268.0], \"sizemode\": \"area\", \"sizeref\": 0.0268, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1313.757337206595, 410.3109459134109, 4330.607180466562, 2834.5780271342787, 5563.4599867644165, 9352.989822219097, 891.4308888098815], \"xaxis\": \"x\", \"y\": [0.9186842105263158, 0.9251315789473684, 0.8940789473684211, 0.9140789473684211, 0.9021052631578947, 0.88, 0.9275], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"itemsizing\": \"constant\", \"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy vs GPU batches prediction speed and model artefact size (Mb)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Prediction speed (sentences/sec) at max batch size\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Accuracy on the test-set\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d27dcf83-4d8c-4329-b754-c41470565897');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPZm0QfL_0Xq"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nblcqTzk_2E5"
      },
      "source": [
        "Some points to be made:\r\n",
        "\r\n",
        "\r\n",
        "1.   **Albert and Mobilebert** were a bit beefier and slower than we had expected them to be, in all honesty. Could be that we did something wrong, or that an implementation quirk in Huggingface gave worse performance than expected.\r\n",
        "2.   Very pleasantly surprised with the **baby-BERT** models. Especially the BERT-small seems to provide a nice-tradeoff.\r\n",
        "3.   **Google** apparently REALLY ‚ù§Ô∏è small models, almost all of the candidates came from them.\r\n",
        "4.   **No GPU** for inference? No problem! For inference, the time for a single prediction seems to be relatively okay, depending on the use-case of course.\r\n",
        "5.   **# Parameters isn't everything**. TinyBERT for example has more parameters than Albert, but still seems to be speedier ü§î. Implementation-differences can have a profound effect.\r\n",
        "\r\n",
        "\r\n",
        "So all in all, depending on your scenario, there are plenty of options to look into. A base BERT doesn't have to be your initial step.\r\n",
        "\r\n",
        "Albeit if you want quicker experimentation, or if you want a faster running application, and you don't HAVE to necessarily have the best possible performance: there are a ton of great options to check out."
      ]
    }
  ]
}