{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncXWQvfOH1CI"
      },
      "source": [
        "# ðŸ”­ Gender Bias in Word Embeddings ðŸ‘«\n",
        "\n",
        "This notebook focuses on the existence of gender stereotypes in datasets and how to mitigate it through clever NLP!\n",
        "\n",
        "We'll train a word2vec model on the WikiBio dataset and look into the gender bias that exists in the learned vectors. Then, we'll apply Counterfactual Data Augmentation (CDA) method in our data to reduce bias and train a word2vec model on the new data.\n",
        "\n",
        "We hope that the new learned vectors will present less gender bias ðŸ˜Ž.\n",
        "\n",
        "Of course, this is just one simple technique to try and mitigate (gender) bias in documents. There exist many more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkoNfTSd21g6"
      },
      "source": [
        "## ðŸ› ï¸ Getting started\n",
        "\n",
        "The cells below will setup everything that is required to get started with data loading using HuggingFace and training word2vec models using Gensim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQXfI15jQb1C"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8uFMXmmHzUY",
        "outputId": "94002f3f-10f5-4883-a739-2e5c2141a77e"
      },
      "outputs": [],
      "source": [
        "!apt-get install python3-magic\n",
        "!pip install -q gensim datasets augly gender-bender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTGe29mcQe-7"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLiKoNuq1MLn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import augly.text as textaugs\n",
        "from gender_bender import gender_bend\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from datasets import concatenate_datasets, Dataset, load_from_disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipA94F-h01Px"
      },
      "source": [
        "### Download dataset\n",
        "\n",
        "We'll train our word vectors on the [Wiki-Bio](https://rlebret.github.io/wikipedia-biography-dataset/) dataset, which is a collection various biography pages from Wikipedia. This seems like an ideal candidate for our gender-bias experiment.\n",
        "\n",
        "We pre-downloaded the dataset from the Github page. If you are unable to do so, feel free to just load in our preprocessed dataset in the section **Load in the data**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdIlM9fPT4SS"
      },
      "outputs": [],
      "source": [
        "wiki_bio_sent = []\n",
        "wiki_bio_nb = []\n",
        "wiki_bio_title = []\n",
        "wiki_bio_id = []\n",
        "\n",
        "with open('wikipedia-biography-dataset/test/test.sent', 'r') as f:\n",
        "    wiki_bio_sent = f.read().splitlines() \n",
        "\n",
        "with open('wikipedia-biography-dataset/test/test.nb', 'r') as f:\n",
        "    wiki_bio_nb = f.read().splitlines()\n",
        "\n",
        "with open('wikipedia-biography-dataset/test/test.title', 'r') as f:\n",
        "    wiki_bio_title = f.read().splitlines() \n",
        "\n",
        "with open('wikipedia-biography-dataset/test/test.id', 'r') as f:\n",
        "    wiki_bio_id = f.read().splitlines() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvu9vWdiT4SZ"
      },
      "source": [
        "It's in a bit of a weird format, so we'll have to merge it together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KldSaS8bT4Sc"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "wiki_bio_sent_grouped = []\n",
        "for nr in wiki_bio_nb:\n",
        "    nr_int = int(nr)\n",
        "    wiki_sent_slice = wiki_bio_sent[i:i+nr_int]\n",
        "    wiki_bio_sent_grouped.append(' '.join(wiki_sent_slice))\n",
        "    i+=nr_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZC3N9cUT4Sf"
      },
      "outputs": [],
      "source": [
        "df_data = pd.DataFrame({\n",
        "    'text': wiki_bio_sent_grouped,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC1Qn5AUT4Si"
      },
      "outputs": [],
      "source": [
        "# Create a HF dataset object\n",
        "hf_data = Dataset.from_pandas(df_data)\n",
        "hf_data.save_to_disk('./data/hf_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpigL1sxuelX"
      },
      "source": [
        "## Counterfactual Data Augmentation (CDA) ðŸ§‘ ðŸ‘©\n",
        "\n",
        "To reduce gender bias in our dataset, we can use CDA, a technique that replaces every occurrence of a gendered word in the original corpus with its dual. For example:\n",
        "- 'he' is replaced by 'she'\n",
        "- 'actor' is replaced by 'actress'\n",
        "- 'king' is replaced by 'queen'\n",
        "\n",
        "Then, we concatenate the generated samples with the original ones to create our final dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyG6oBz7T4Sw"
      },
      "source": [
        "### Library to use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEOqQ--exsix"
      },
      "source": [
        "We'll quickly look at two libraries that can do this augmentation:\n",
        "- [AugLy](https://github.com/facebookresearch/AugLy): data augmentations library to swap the gendered words. \n",
        "- [GenderBender](https://github.com/Garrett-R/gender_bender): a slightly older but seemingly robust library.\n",
        "Let's see an example of these methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuzONAsmxtnV",
        "outputId": "81bbd90f-cc7e-43e8-944d-37ad0ec01c88"
      },
      "outputs": [],
      "source": [
        "gendered_text = \"She has two sisters, but she always wanted a brother\"\n",
        "aug_augly = textaugs.SwapGenderedWords(aug_word_p=1.0)(gendered_text)\n",
        "aug_genderbender = gender_bend(gendered_text)\n",
        "\n",
        "print(f\"AugLy: {aug_augly}\")\n",
        "print(f\"GenderBender: {aug_genderbender}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVSnvYJmXU9K",
        "outputId": "2bdd1d7e-8b0f-4460-cf1c-8ef6dfea9d0c"
      },
      "outputs": [],
      "source": [
        "gendered_text = \"She is a waitress, but she is studying to pay for her college education.\"\n",
        "aug_augly = textaugs.SwapGenderedWords(aug_word_p=1.0)(gendered_text)\n",
        "aug_genderbender = gender_bend(gendered_text)\n",
        "\n",
        "print(f\"AugLy: {aug_augly}\")\n",
        "print(f\"GenderBender: {aug_genderbender}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_VCuImxT4S_"
      },
      "source": [
        "It turns out both seem to have their problems with some words, as both methods rely heavily on lists of gendered words.\n",
        "\n",
        "But for now, we'll continue to use GenderBender. So let's apply the function to our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43OokVjTT4TA"
      },
      "source": [
        "### Apply to the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M126iAzxCyi"
      },
      "outputs": [],
      "source": [
        "# swap gendered words in each sample of the dataset\n",
        "# hf_data_cda = hf_data.map(lambda e: {'text': gender_bend(e['text'])})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSI8Je9PT4TI"
      },
      "source": [
        "This can take quite a LONG time to perform. So for speed purposes, we performed this operation in a distributed fashion on Google Cloud DataFlow, using Apache Beam, and wrote the result to a new textfile. \n",
        "\n",
        "If you want to skip this step, feel free to load in the HuggingFace datasets directly in the cell after."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60BlRlfLT4TJ"
      },
      "outputs": [],
      "source": [
        "wiki_bio_sent_cda = []\n",
        "\n",
        "with open('wikipedia-biography-dataset/test_joined.txt', 'r') as f:\n",
        "    wiki_bio_sent_cda = f.read().splitlines() \n",
        "\n",
        "df_data_cda = pd.DataFrame({\n",
        "    'text': wiki_bio_sent_cda,\n",
        "})\n",
        "\n",
        "hf_data_cda = Dataset.from_pandas(df_data_cda)\n",
        "hf_data_cda.save_to_disk('./data/hf_data_cda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFb7oADST4TL"
      },
      "source": [
        "### Load in the data\n",
        "Load in the pre-processed data directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h49ZpgTBT4TM",
        "outputId": "2b1cc856-df04-42c3-a42d-1098d346c90a"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ml6team/quick-tips.git\n",
        "!cd quick-tips \n",
        "!mv quick-tips/nlp/gender_debiasing_cda/data ./data\n",
        "!rm -rf quick-tips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEgPH0vqT4TO"
      },
      "outputs": [],
      "source": [
        "hf_data_cda=load_from_disk('./data/hf_data_cda')\n",
        "hf_data=load_from_disk('./data/hf_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LpV6dwnT4TO"
      },
      "source": [
        "Let's look at some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO7k23iWT4TP",
        "outputId": "442b1141-ca40-46a9-cc95-6344e89c0f66"
      },
      "outputs": [],
      "source": [
        "hf_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTquL2AvT4TR",
        "outputId": "3bb46ce5-3876-4748-c4c2-da0a1c6d547d"
      },
      "outputs": [],
      "source": [
        "hf_data_cda[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MpIw7Gi0YKJ"
      },
      "source": [
        "## Measure Bias ðŸ“\n",
        "\n",
        "Finally, we want to measure the bias that exists in each embedding. There are various ways to measure the bias present in a learned embedding. Let's try some of them:\n",
        "- Word cosine similarity\n",
        "- Gender vector decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KQntXeoT4TT"
      },
      "source": [
        "### Word embeddings model\n",
        "\n",
        "Both methods rely on a word embeddings model to be made, so that will be our first goal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5AWzbtST4TU"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec,KeyedVectors\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb4LGgKHT4TU"
      },
      "outputs": [],
      "source": [
        "epochs=5\n",
        "vector_size=300\n",
        "window=5\n",
        "min_count=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HneGDI2VT4TV"
      },
      "source": [
        "Prepare the dataset for gensim processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-vrwQiMT4TZ"
      },
      "outputs": [],
      "source": [
        "def gensim_preprocess(text):\n",
        "    return simple_preprocess(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "816d13514a5d4387bd36991a145125c3",
            "0e8cffe8b20e4cf9a6414636028742a6"
          ]
        },
        "id": "oASSyi0mT4Ta",
        "outputId": "418c485b-ae1b-4df1-9162-c28f922dd0f5"
      },
      "outputs": [],
      "source": [
        "hf_data_cda_split=hf_data_cda.map(lambda e: {'text': gensim_preprocess(e['text'])})\n",
        "hf_data_split=hf_data.map(lambda e: {'text': gensim_preprocess(e['text'])})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUVdxOckT4Tb"
      },
      "source": [
        "Create a new artificial dataset that combines both the debiased and biased form, to hopefully balance things out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKapGkNmT4Td"
      },
      "outputs": [],
      "source": [
        "hf_data_merged=concatenate_datasets([hf_data_split, hf_data_split])\n",
        "hf_data_cda_merged=concatenate_datasets([hf_data_cda_split, hf_data_split])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbBdbl8OT4Td"
      },
      "source": [
        "#### Train non debiased word embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KqwKOGQT4Te",
        "outputId": "02c73eac-3dc7-4e66-db54-2f60443e1873"
      },
      "outputs": [],
      "source": [
        "model_wikibio = Word2Vec(\n",
        "    vector_size=vector_size,\n",
        "    window=window,\n",
        "    min_count=min_count,\n",
        "    workers=multiprocessing.cpu_count()-1)\n",
        "\n",
        "model_wikibio.build_vocab(hf_data_merged['text'], progress_per=10000)\n",
        "\n",
        "model_wikibio.train(\n",
        "    hf_data_merged['text'],\n",
        "    total_examples=model_wikibio.corpus_count,\n",
        "    epochs=epochs,\n",
        "    report_delay=10)\n",
        "\n",
        "vec_wikibio = model_wikibio.wv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_RQ6dG9T4Tg"
      },
      "source": [
        "#### Train debaised word embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCidWBsDT4Tg",
        "outputId": "6b76024c-3529-431b-8662-018938224ea0"
      },
      "outputs": [],
      "source": [
        "model_unbiased_wikibio = Word2Vec(\n",
        "    vector_size=vector_size,\n",
        "    window=window,\n",
        "    min_count=min_count,\n",
        "    workers=multiprocessing.cpu_count()-1)\n",
        "\n",
        "model_unbiased_wikibio.build_vocab(hf_data_cda_merged['text'], progress_per=10000)\n",
        "\n",
        "model_unbiased_wikibio.train(\n",
        "    hf_data_cda_merged['text'],\n",
        "    total_examples=model_unbiased_wikibio.corpus_count,\n",
        "    epochs=epochs,\n",
        "    report_delay=10)\n",
        "\n",
        "vec_unbiased_wikibio = model_unbiased_wikibio.wv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSCM2Wae_4qJ"
      },
      "source": [
        "### Cosine similarity\n",
        "\n",
        "To check how close two vectors are we can use cosine similarity. The similarity as a single number does not reveal much about the bias. However, we can compare the similarity of a word with some gendered words. For example, the word 'doctor' should have equal similarity with the words 'man' and 'woman' since a doctor can be either a man or a woman.\n",
        "\n",
        "For completeness sake, we use a number of gendered words and average out the similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ur2TSv7T4Ti"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "gender_words = ['pilot', 'engineer', 'professor', 'judge']\n",
        "\n",
        "gender_pairs = [\n",
        "      (\"she\", \"he\"),\n",
        "      (\"girl\", \"boy\"),\n",
        "      (\"woman\", \"man\")]\n",
        "\n",
        "before_avg = []\n",
        "after_avg =[]\n",
        "\n",
        "for word in gender_words:\n",
        "    \n",
        "    before = []\n",
        "    after = []\n",
        "\n",
        "    for female, male in gender_pairs:\n",
        "        before_m = 1 - spatial.distance.cosine(vec_wikibio[word], vec_wikibio[male])\n",
        "        before_f = 1 - spatial.distance.cosine(vec_wikibio[word], vec_wikibio[female])\n",
        "        after_m = 1 - spatial.distance.cosine(vec_unbiased_wikibio[word], vec_unbiased_wikibio[male])\n",
        "        after_f = 1 - spatial.distance.cosine(vec_unbiased_wikibio[word], vec_unbiased_wikibio[female])\n",
        "\n",
        "        before.append(before_m - before_f)\n",
        "        after.append(after_m - after_f)\n",
        "    \n",
        "    before_avg.append(sum(before)/len(before))\n",
        "    after_avg.append(sum(after)/len(after))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZBRgTcOT4Tj",
        "outputId": "d03149b1-ed1b-4f95-9aa4-77221b92ee73"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Raw dataset', x=gender_words, y=before_avg),\n",
        "    go.Bar(name='Debiased dataset', x=gender_words, y=after_avg)\n",
        "])\n",
        "# Change the bar mode\n",
        "fig.update_layout(\n",
        "    title=\"Cosine similarity bias measure\",\n",
        "    xaxis_title=\"Professions\",\n",
        "    yaxis_title=\"Similarity difference\",\n",
        "    barmode='group')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIZGTe7otX7d"
      },
      "source": [
        "The chart above shows the difference between 'male' keywords and 'female' keywords for the given profession. The larger this difference, the more gender bias is present in the word embeddings, and thus in the dataset.\n",
        "\n",
        "We observe that using this method, the bias indeed seems to be reduced!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrnc-Eu3hi2x"
      },
      "source": [
        "### Finding the gender vector\n",
        "\n",
        "Our goal here is to find a \"gender\" dimension in the data. This is done by subtracting words that are known to be male from their equivalent female version. In each of these cases, the words are nearly identical in all ways except for the gender they refer to. As such, subtracting these words should result in a vector that mostly represents the idea of â€œgenderâ€."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgyGIFcmryAa"
      },
      "outputs": [],
      "source": [
        "gender_pairs = [\n",
        "      (\"girl\", \"boy\"),\n",
        "      (\"she\", \"he\"),\n",
        "      (\"woman\", \"man\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvDKyNVy5jvr"
      },
      "outputs": [],
      "source": [
        "gender_vectors = []\n",
        "for (female_word, male_word) in gender_pairs:\n",
        "    gender_vectors.append(vec_wikibio[female_word] - vec_wikibio[male_word])\n",
        "    gender_vectors.append(vec_wikibio[male_word] - vec_wikibio[female_word])\n",
        "\n",
        "pca = PCA(n_components=1)\n",
        "pca.fit(np.array(gender_vectors))\n",
        "\n",
        "female_vector = np.mean(\n",
        "  pca.transform(np.array([vec_wikibio[pair[0]] for pair in gender_pairs]))\n",
        ")\n",
        "male_vector = np.mean(\n",
        "  pca.transform(np.array([vec_wikibio[pair[1]] for pair in gender_pairs]))\n",
        ")\n",
        "mean_projection = (male_vector + female_vector) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qbI_g7_rvfx"
      },
      "outputs": [],
      "source": [
        "gender_vectors_unbiased = []\n",
        "for (female_word, male_word) in gender_pairs:\n",
        "    gender_vectors_unbiased.append(vec_unbiased_wikibio[female_word] - vec_unbiased_wikibio[male_word])\n",
        "    gender_vectors_unbiased.append(vec_unbiased_wikibio[male_word] - vec_unbiased_wikibio[female_word])\n",
        "\n",
        "pca_unbiased = PCA(n_components=1)\n",
        "pca_unbiased.fit(np.array(gender_vectors_unbiased))\n",
        "\n",
        "female_vector_unbiased = np.mean(\n",
        "  pca_unbiased.transform(np.array([vec_unbiased_wikibio[pair[0]] for pair in gender_pairs])) \n",
        ")\n",
        "male_vector_unbiased = np.mean(\n",
        "  pca_unbiased.transform(np.array([vec_unbiased_wikibio[pair[1]] for pair in gender_pairs]))\n",
        ")\n",
        "mean_projection_unbiased = (male_vector_unbiased + female_vector_unbiased) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2MBLLoDr_WJ"
      },
      "outputs": [],
      "source": [
        "jobs = [\"singer\", \"teacher\", \"doctor\", \"pilot\", \"developer\",  \"lawyer\",  \"coach\", \"engineer\", 'scientist']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvjQFYScswqN"
      },
      "source": [
        "Now, for each job let's compute how close it is to the 'male' and the 'female' vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SauPV5GaT4Ty"
      },
      "outputs": [],
      "source": [
        "vec_before = []\n",
        "vec_after = []\n",
        "\n",
        "for word in jobs:\n",
        "    word_biased = pca.transform(np.array([vec_wikibio[word]]))[0][0]\n",
        "    word_unbiased = pca_unbiased.transform(np.array([vec_unbiased_wikibio[word]]))[0][0]\n",
        "    # scale the score so > 0 means female bias, < 0 means male bias\n",
        "    biased = 2 * (word_biased - mean_projection) / (female_vector - male_vector)\n",
        "    unbiased = 2 * (word_unbiased - mean_projection_unbiased) / (female_vector_unbiased - male_vector_unbiased)\n",
        "    vec_before.append(biased)\n",
        "    vec_after.append(unbiased)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XV37DKzT4T0",
        "outputId": "8da18f2b-23d9-4114-c2fb-33c04f02fd95"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Raw dataset', x=jobs, y=vec_before),\n",
        "    go.Bar(name='Debiased dataset', x=jobs, y=vec_after)\n",
        "])\n",
        "# Change the bar mode\n",
        "fig.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"Gender vector bias measure\",\n",
        "    xaxis_title=\"Professions\",\n",
        "    yaxis_title=\"Similarity difference\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgZ7iENItahT"
      },
      "source": [
        "We observe that in mane cases CDA manages to reduce bias, or even flip it slightly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwBXyT8VzEM_"
      },
      "source": [
        "## Take-aways ðŸ¤“\n",
        "\n",
        "You've reached the finish line! ðŸ‘ Let's summarize some of the findings.\n",
        "\n",
        "- We applied the CDA technique in a dataset to reduce the impact of gender bias.\n",
        "- Then, we trained word2vec models on both the original and the CDA-augmented datasets.\n",
        "- We measured the bias present in the vectors using 2 methods: cosine similarity and finding the gender vectors.\n",
        "- We observed that there are indeed indications that the CDA method works to reduce gender bias. Of course, there isn't a single unified method to measure bias!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "gender_debiasing_cda.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "pytorch-gpu.1-10.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
